{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPFL",
      "provenance": [],
      "collapsed_sections": [
        "jCOONkg-zV7Y",
        "ctjRsETiO1qO"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63a9176ac65e4443bf34501cbffb503f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a53afb7c5e144827b3011c0a49743a85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_695ac0d8c8ce4348b701a71ae12f421d",
              "IPY_MODEL_d72d98aaa1bc4635ae366553616368ee"
            ]
          }
        },
        "a53afb7c5e144827b3011c0a49743a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "695ac0d8c8ce4348b701a71ae12f421d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_374b5474306047be9e65ba12f95ded06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94d92d947dd64fb282cf0f14fdcec1d5"
          }
        },
        "d72d98aaa1bc4635ae366553616368ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94b82f12dfa842e2acc5f75537365924",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [04:44&lt;00:00, 34790.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f2ac97b2e7e42db994b1fea56a60536"
          }
        },
        "374b5474306047be9e65ba12f95ded06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94d92d947dd64fb282cf0f14fdcec1d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94b82f12dfa842e2acc5f75537365924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f2ac97b2e7e42db994b1fea56a60536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a97d3541ac047f78ba5359f0adcf64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b8a5014c4f24c2089d782106550e312",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3aad8bb50c3a4893bc2046ba63a67682",
              "IPY_MODEL_0d6cc7ef2f224fa696dd77344d57452e"
            ]
          }
        },
        "2b8a5014c4f24c2089d782106550e312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3aad8bb50c3a4893bc2046ba63a67682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00ea958592334ca2bd42367e550bfa65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_940a4f6b7f944bc7a492318ad0a1db8f"
          }
        },
        "0d6cc7ef2f224fa696dd77344d57452e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb5564030b60477eb3bd44059c69b385",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:01&lt;00:00, 26004.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d07e2ade525a4bd08f5b66d0ada582da"
          }
        },
        "00ea958592334ca2bd42367e550bfa65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "940a4f6b7f944bc7a492318ad0a1db8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb5564030b60477eb3bd44059c69b385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d07e2ade525a4bd08f5b66d0ada582da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84d26026ad8442e886a4880169b2be70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4b8025cb15d44857b7a8960330206ba4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69bdf65f36a742ce9a89ff631836f316",
              "IPY_MODEL_8ab6f727a7e14aad96818031c8cd7f7f"
            ]
          }
        },
        "4b8025cb15d44857b7a8960330206ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69bdf65f36a742ce9a89ff631836f316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0bc0225fccc4ce69e648366361e8ad3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90d9a0dd181e401dbfd806e92d33ea05"
          }
        },
        "8ab6f727a7e14aad96818031c8cd7f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c4dade60fb349fe9d9c2c423ea6a553",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:53&lt;00:00, 30605.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33374731649d48f0a4201cbcc364a9c4"
          }
        },
        "b0bc0225fccc4ce69e648366361e8ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90d9a0dd181e401dbfd806e92d33ea05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c4dade60fb349fe9d9c2c423ea6a553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33374731649d48f0a4201cbcc364a9c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "940f8528b0af46aca31ddb99e5034f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71dce687c0d54c34b7fb5d08c36a128b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_46564641d71442e5a48f03ce39580554",
              "IPY_MODEL_844d10f37b7043c39354ff74d4d82b10"
            ]
          }
        },
        "71dce687c0d54c34b7fb5d08c36a128b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46564641d71442e5a48f03ce39580554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f217578d63344689a77557892b62b63b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41f1d528bbb04d51ada6982a5e60e7ee"
          }
        },
        "844d10f37b7043c39354ff74d4d82b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f0f4049d9ec4dcf9e28fa74e57267bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:02&lt;00:00, 2004.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86f865ad6e8c44ad944b5bf12d017538"
          }
        },
        "f217578d63344689a77557892b62b63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41f1d528bbb04d51ada6982a5e60e7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f0f4049d9ec4dcf9e28fa74e57267bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86f865ad6e8c44ad944b5bf12d017538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "236955630f214239a6d5886a07924b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1348a937efe145ab90d5554273824333",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7fc77edf264481ead62cf522e781ca2",
              "IPY_MODEL_aae7557563eb4018b063338ba30eaf89"
            ]
          }
        },
        "1348a937efe145ab90d5554273824333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7fc77edf264481ead62cf522e781ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03f78c7c06394e13a911ac3e69e25980",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_374a3606d4ec4b30ac66613c9f29e71f"
          }
        },
        "aae7557563eb4018b063338ba30eaf89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5872b5605c08407880c3e8735db38947",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:01&lt;00:00, 6680431.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35bc46ada8d342ce81d7723ecd5b242e"
          }
        },
        "03f78c7c06394e13a911ac3e69e25980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "374a3606d4ec4b30ac66613c9f29e71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5872b5605c08407880c3e8735db38947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35bc46ada8d342ce81d7723ecd5b242e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd1e9e931a9d4f61a770eecde504488d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53389681eae74c84b688dea116aa2bff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cd676e1d9db4a72ba2f05650da77e10",
              "IPY_MODEL_862e4d07769242de9a3f8e7ae4db50dd"
            ]
          }
        },
        "53389681eae74c84b688dea116aa2bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cd676e1d9db4a72ba2f05650da77e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_937e242d04174455aa9e1ed814d4e7a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7f73c98e85246d4a1a5a3b955933cc8"
          }
        },
        "862e4d07769242de9a3f8e7ae4db50dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be55d43f15ff479e9bd6d46020b35bcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:50&lt;00:00, 591.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64a0128417a340eebf1740d7c59d91fa"
          }
        },
        "937e242d04174455aa9e1ed814d4e7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7f73c98e85246d4a1a5a3b955933cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be55d43f15ff479e9bd6d46020b35bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64a0128417a340eebf1740d7c59d91fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2693e13206fc4a1c8950a06797c99629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_11bfe2002bdf410c8bda0ed571af6e4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d5be08802c194980997491460a89946f",
              "IPY_MODEL_f880817afa2744feb305d9da764cd535"
            ]
          }
        },
        "11bfe2002bdf410c8bda0ed571af6e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5be08802c194980997491460a89946f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b6fd88851e3648179611156dd0cf9e16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be7917c0e9864c20bd30cec056bfaa67"
          }
        },
        "f880817afa2744feb305d9da764cd535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_846119fdce1d43e3b38949990dc15fb8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:49&lt;00:00, 33213.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c56eef7118446efa6fd3ebc57b05072"
          }
        },
        "b6fd88851e3648179611156dd0cf9e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be7917c0e9864c20bd30cec056bfaa67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "846119fdce1d43e3b38949990dc15fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c56eef7118446efa6fd3ebc57b05072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6af57f8b99574bbb9427e4d28684be3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e7e1f58b66c495583d4b980118eaa63",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b7ee47442ad466687800d90fada6882",
              "IPY_MODEL_ae35492040474302b2f1faa3d490638c"
            ]
          }
        },
        "5e7e1f58b66c495583d4b980118eaa63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b7ee47442ad466687800d90fada6882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_901c30a65f1141b48977519770303b80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_886a52a2f4d4401f83f742de23b8aafb"
          }
        },
        "ae35492040474302b2f1faa3d490638c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4e6477e198a4924bc4fec2be094d045",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 51857.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e52b7650d47d4c5bb7bfb1c6efb590e6"
          }
        },
        "901c30a65f1141b48977519770303b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "886a52a2f4d4401f83f742de23b8aafb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4e6477e198a4924bc4fec2be094d045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e52b7650d47d4c5bb7bfb1c6efb590e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_BwkvTfe8ry",
        "outputId": "0c18eabc-19b9-4d9f-ba18-c9d478cbcf8c"
      },
      "source": [
        "!pip install opacus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-0.14.0-py3-none-any.whl (114 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 61 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 71 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 102 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 112 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 114 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.9.0+cu102)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->opacus) (3.7.4.3)\n",
            "Installing collected packages: opacus\n",
            "Successfully installed opacus-0.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNmNbEqgfHq5"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torchsummary import summary\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from opacus.utils.uniform_sampler import UniformWithReplacementSampler\n",
        "from torchvision import models\n",
        "from opacus.dp_model_inspector import DPModelInspector\n",
        "from opacus.utils import module_modification\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from opacus import PrivacyEngine\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLLNM9X2JbQ8",
        "outputId": "fdf3dc22-b9a9-4187-8b5a-d68a244066aa"
      },
      "source": [
        "%load_ext tensorboard\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "# Check assigned GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# set manual seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# general reproducibility\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# gpu training specific\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 20 20:05:09 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY4eWzGiL6Mj"
      },
      "source": [
        "## Load the MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrQqtf-ziZxS"
      },
      "source": [
        "MAX_GRAD_NORM = 1.2\n",
        "EPSILON = 0.5\n",
        "DELTA = 1e-5\n",
        "EPOCHS = 5\n",
        "\n",
        "LR = 1e-3\n",
        "NUM_WORKERS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwxCDkoziZO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd34edff-b086-4e38-9fbd-5e403ef8323b"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "VIRTUAL_BATCH_SIZE = 512\n",
        "assert VIRTUAL_BATCH_SIZE % BATCH_SIZE == 0 # VIRTUAL_BATCH_SIZE should be divisible by BATCH_SIZE\n",
        "N_ACCUMULATION_STEPS = int(VIRTUAL_BATCH_SIZE / BATCH_SIZE)\n",
        "print(N_ACCUMULATION_STEPS)\n",
        "MNIST_MEAN = (0.1307)\n",
        "MNIST_STD_DEV = (0.3081)\n",
        "transforms_mnist = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(MNIST_MEAN,MNIST_STD_DEV)\n",
        "                                       ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G649tjTXLL8F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63a9176ac65e4443bf34501cbffb503f",
            "a53afb7c5e144827b3011c0a49743a85",
            "695ac0d8c8ce4348b701a71ae12f421d",
            "d72d98aaa1bc4635ae366553616368ee",
            "374b5474306047be9e65ba12f95ded06",
            "94d92d947dd64fb282cf0f14fdcec1d5",
            "94b82f12dfa842e2acc5f75537365924",
            "5f2ac97b2e7e42db994b1fea56a60536",
            "5a97d3541ac047f78ba5359f0adcf64d",
            "2b8a5014c4f24c2089d782106550e312",
            "3aad8bb50c3a4893bc2046ba63a67682",
            "0d6cc7ef2f224fa696dd77344d57452e",
            "00ea958592334ca2bd42367e550bfa65",
            "940a4f6b7f944bc7a492318ad0a1db8f",
            "eb5564030b60477eb3bd44059c69b385",
            "d07e2ade525a4bd08f5b66d0ada582da",
            "84d26026ad8442e886a4880169b2be70",
            "4b8025cb15d44857b7a8960330206ba4",
            "69bdf65f36a742ce9a89ff631836f316",
            "8ab6f727a7e14aad96818031c8cd7f7f",
            "b0bc0225fccc4ce69e648366361e8ad3",
            "90d9a0dd181e401dbfd806e92d33ea05",
            "2c4dade60fb349fe9d9c2c423ea6a553",
            "33374731649d48f0a4201cbcc364a9c4",
            "940f8528b0af46aca31ddb99e5034f18",
            "71dce687c0d54c34b7fb5d08c36a128b",
            "46564641d71442e5a48f03ce39580554",
            "844d10f37b7043c39354ff74d4d82b10",
            "f217578d63344689a77557892b62b63b",
            "41f1d528bbb04d51ada6982a5e60e7ee",
            "5f0f4049d9ec4dcf9e28fa74e57267bd",
            "86f865ad6e8c44ad944b5bf12d017538",
            "236955630f214239a6d5886a07924b75",
            "1348a937efe145ab90d5554273824333",
            "f7fc77edf264481ead62cf522e781ca2",
            "aae7557563eb4018b063338ba30eaf89",
            "03f78c7c06394e13a911ac3e69e25980",
            "374a3606d4ec4b30ac66613c9f29e71f",
            "5872b5605c08407880c3e8735db38947",
            "35bc46ada8d342ce81d7723ecd5b242e",
            "cd1e9e931a9d4f61a770eecde504488d",
            "53389681eae74c84b688dea116aa2bff",
            "9cd676e1d9db4a72ba2f05650da77e10",
            "862e4d07769242de9a3f8e7ae4db50dd",
            "937e242d04174455aa9e1ed814d4e7a0",
            "e7f73c98e85246d4a1a5a3b955933cc8",
            "be55d43f15ff479e9bd6d46020b35bcd",
            "64a0128417a340eebf1740d7c59d91fa",
            "2693e13206fc4a1c8950a06797c99629",
            "11bfe2002bdf410c8bda0ed571af6e4b",
            "d5be08802c194980997491460a89946f",
            "f880817afa2744feb305d9da764cd535",
            "b6fd88851e3648179611156dd0cf9e16",
            "be7917c0e9864c20bd30cec056bfaa67",
            "846119fdce1d43e3b38949990dc15fb8",
            "2c56eef7118446efa6fd3ebc57b05072",
            "6af57f8b99574bbb9427e4d28684be3a",
            "5e7e1f58b66c495583d4b980118eaa63",
            "1b7ee47442ad466687800d90fada6882",
            "ae35492040474302b2f1faa3d490638c",
            "901c30a65f1141b48977519770303b80",
            "886a52a2f4d4401f83f742de23b8aafb",
            "a4e6477e198a4924bc4fec2be094d045",
            "e52b7650d47d4c5bb7bfb1c6efb590e6"
          ]
        },
        "outputId": "4f63e659-1f2d-4efe-b8d8-8914c31b5fff"
      },
      "source": [
        "# create transforms\n",
        "# We will just convert to tensor and normalize since no special transforms are mentioned in the paper\n",
        "# transforms_mnist = transforms.Compose([\n",
        "#                                        transforms.ToTensor(),\n",
        "#                                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                                        ])\n",
        "\n",
        "mnist_data_train = datasets.MNIST('./data/mnist/', train=True, download=True, transform=transforms_mnist)\n",
        "mnist_data_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=transforms_mnist)\n",
        "\n",
        "SAMPLE_RATE = BATCH_SIZE / len(mnist_data_train)\n",
        "print(SAMPLE_RATE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63a9176ac65e4443bf34501cbffb503f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a97d3541ac047f78ba5359f0adcf64d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d26026ad8442e886a4880169b2be70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "940f8528b0af46aca31ddb99e5034f18",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "236955630f214239a6d5886a07924b75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd1e9e931a9d4f61a770eecde504488d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2693e13206fc4a1c8950a06797c99629",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6af57f8b99574bbb9427e4d28684be3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
            "\n",
            "0.0021333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm9usjn2vFkL",
        "outputId": "1e3d900f-18c1-455d-b845-1c18d96a4da3"
      },
      "source": [
        "classes = np.array(list(mnist_data_train.class_to_idx.values()))\n",
        "classes_test = np.array(list(mnist_data_test.class_to_idx.values()))\n",
        "num_classes = len(classes_test)\n",
        "print(\"Classes: {} \\tType: {}\".format(classes, type(classes)))\n",
        "print(\"Classes Test: {} \\tType: {}\".format(classes_test, type(classes)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classes: [0 1 2 3 4 5 6 7 8 9] \tType: <class 'numpy.ndarray'>\n",
            "Classes Test: [0 1 2 3 4 5 6 7 8 9] \tType: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lvJt3Ofv2SO",
        "outputId": "ac6cd7fc-b378-4f0e-b848-4fd55c00586b"
      },
      "source": [
        "print(\"Image Shape: {}\".format(mnist_data_train.data[0].size()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Shape: torch.Size([28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCOONkg-zV7Y"
      },
      "source": [
        "## Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9MK03TZw6Qs"
      },
      "source": [
        "def imshow(img):\n",
        "\timg = img/2 + 0.5 #unnormalize the image\n",
        "\tplt.imshow(img,cmap='gray') # convert from tensor to image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMJ0Kx4Kw-_H"
      },
      "source": [
        "def visualize(dataset):\n",
        "  figure = plt.figure(figsize=(25,4))\n",
        "  for i in range(20):\n",
        "    axis = figure.add_subplot(2, 20/2, i+1, xticks=[], yticks=[])\n",
        "    data = dataset.data[i]\n",
        "    data = data.numpy()\n",
        "\n",
        "    target = dataset.targets[i]\n",
        "    target = target.numpy()\n",
        "    imshow(data)\n",
        "    axis.set_title(target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "8bPOwKg10Ro7",
        "outputId": "e6596799-8d5f-44b2-e088-b847e72e640b"
      },
      "source": [
        "visualize(mnist_data_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABXEAAAD7CAYAAAAsAtcsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de9xNdfbA8fV1JyGUrujifk+JRjFCpUKKyKXUTKVfdCNdVCakpCuVpNSUSZJLpciESlJJmnENhYhckvs1+/fHY77zXd/pnM5znPPsfZ7n8369vH5rzTpn7/Wr3T77fO29jgmCQAAAAAAAAAAA0ZQv7AYAAAAAAAAAALGxiAsAAAAAAAAAEcYiLgAAAAAAAABEGIu4AAAAAAAAABBhLOICAAAAAAAAQISxiAsAAAAAAAAAEcYiLgAAAAAAAABEWJ5ZxDXGzDLG7DXG7Dz8Z1nYPSH6jDGljTETjTG7jDGrjTFXh90TMocxptLh887rYfeCaDPG3GKMmWeM2WeMeSXsfpA5jDHVjDEzjDHbjDErjDGXh90Tos0YU9gY89Lh65odxpgFxpiLw+4L0cbnFJJhjHndGLPeGLPdGPOdMeYvYfeE6ON8gyOR27+D55lF3MNuCYKg+OE/VcJuBhnhWRHZLyLlRKSziDxvjKkRbkvIIM+KyFdhN4GM8JOIDBSRl8NuBJnDGFNARCaLyHsiUlpEbhCR140xlUNtDFFXQER+FJEmIlJSRPqJyDhjTMUQe0L08TmFZAwWkYpBEJQQkdYiMtAYUz/knhB9nG9wJHL1d/C8togLJMwYc5SIXCEi9wdBsDMIgtki8o6IdA23M2QCY0xHEflVRD4KuxdEXxAEE4IgmCQiW8LuBRmlqoicKCJPBkHwWxAEM0TkM+FzCnEEQbArCIL+QRCsCoLgUBAE74nIDyLCwgpi4nMKyQiCYFEQBPv+kx7+c3qILSEDcL5BsvLCd/C8tog72Biz2RjzmTGmadjNIPIqi8jBIAi+c/63b0WEO3ERlzGmhIg8JCJ3hN0LgDzHiEjNsJtA5jDGlJOsa55FYfcCIPcxxjxnjNktIktFZL2IvB9ySwByobzyHTwvLeL2FZHTROQkERkpIu8aY/hbQMRTXES2e//bNhE5OoRekFkGiMhLQRCsDbsRALnaMhHZKCJ9jDEFjTEtJesR+WLhtoVMYYwpKCJjROTVIAiWht0PgNwnCIKbJev703kiMkFE9sV/BwAkJU98B88zi7hBEHwRBMGOIAj2BUHwqmQ9btgq7L4QaTtFpIT3v5UQkR0h9IIMYYypKyLNReTJsHsBkLsFQXBARNqKyCUiskFE7hSRcSKSqy9ekRrGmHwi8ppkzf6/JeR2AORih0f+zBaRk0WkR9j9AMhd8tJ38AJhNxCiQLIeOQRi+U5EChhjKgVBsPzw/1ZHeNwQ8TUVkYoissYYI5J1R3d+Y0z1IAjODLEvALlQEAT/kqy7b0VExBgzR0ReDa8jZAKT9QH1kmT9cGurw38hAADpVkCYiQsg9ZpKHvkOnifuxDXGlDLGXGiMKWKMKWCM6Swi54vI1LB7Q3QFQbBLsh75ecgYc5Qx5k8i0kay7loBYhkpWRendQ//GSEiU0TkwjCbQrQd/mwqIiL5JeuCo4gxJi//RSsSZIypffh4KWaM6S0iJ4jIKyG3heh7XkSqichlQRDsCbsZRB+fU8guY8xxxpiOxpjixpj8xpgLRaST5OIfHEJqcL5BEvLMd/A8sYgrIgVFZKCIbBKRzSLSU0Taej9YBfyem0WkqGTNHHxDRHoEQcCduIgpCILdQRBs+M8fyRrLsTcIgk1h94ZI6ycie0TkbhHpcjjuF2pHyBRdJeuHYjaKyAUi0sL5JXDgfxhjKojIjZL1JWeDMWbn4T+dQ24N0cbnFLIrkKzRCWtFZKuIDBWR24IgeCfUrpAJON8gW/LSd3ATBEHYPQAAAAAAAAAAYsgrd+ICAAAAAAAAQEZiERcAAAAAAAAAIoxFXAAAAAAAAACIMBZxAQAAAAAAACDCWMQFAAAAAAAAgAgrkJ0XG2OCdDWCbNscBMGxYTeRCI6b6AiCwITdQyI4ZiKFcw2SwXGDZHDcIBkcN0gGxw2SwXGDbOM7OJIQ81zDnbiZa3XYDQDIEzjXIBkcN0gGxw2SwXGDZHDcIBkcNwByQsxzDYu4AAAAAAAAABBhLOICAAAAAAAAQISxiAsAAAAAAAAAEcYiLgAAAAAAAABEGIu4AAAAAAAAABBhLOICAAAAAAAAQISxiAsAAAAAAAAAEcYiLgAAAAAAAABEGIu4AAAAAAAAABBhLOICAAAAAAAAQISxiAsAAAAAAAAAEcYiLgAAAAAAAABEWIGwGwAyUf369VV+yy232Lhbt26q9ve//93Gw4YNU7X58+enoTsAAAAgOU8//bTKe/XqZeOFCxeq2qWXXqry1atXp68xAAAi5qOPPrKxMUbVmjVrlvL9cScuAAAAAAAAAEQYi7gAAAAAAAAAEGEs4gIAAAAAAABAhOXKmbj58+dXecmSJRN+rzvbtFixYqpWpUoVG//f//2fqg0dOtTGnTp1UrW9e/fa+JFHHlG1v/3tbwn3hvDUrVtX5dOnT1d5iRIlbBwEgap17drVxq1bt1a1MmXKpKpF5BEXXHCBjceMGaNqTZo0sfGyZctyrCdEQ79+/Wzsf7bky/ffv7Nt2rSpqn388cdp7QtAZjj66KNVXrx4cRtfcsklqnbsscfa+IknnlC1ffv2paE7pFvFihVt3KVLF1U7dOiQjatVq6ZqVatWVTkzcfOWypUr27hgwYKqdv7559v4ueeeUzX3mDoSkydPtnHHjh1Vbf/+/SnZB9LLP27OPfdcGz/88MOq9qc//SlHegLiefLJJ1XuHrPu7yGlC3fiAgAAAAAAAECEsYgLAAAAAAAAABEW6XEK5cuXV3mhQoVs7N6yLCLSuHFjG5cqVUrVrrjiipT0s3btWhs/88wzqnb55ZfbeMeOHar27bff2pjHVjNHgwYNbPz222+rmj+iwx2h4P/7dx/l8ccnNGzY0Mbz58+P+T4kxn1sS0T/8544cWJOt5MWZ599to2/+uqrEDtB2K699lqV9+3b18bxHlP0R74AyDvcR+bdc4aISKNGjVRes2bNhLZ5wgknqLxXr17JNYdQbdq0ycaffPKJqvnjwJC31KhRw8b+tUf79u1t7I5uEhE58cQTbexfl6TqWsQ9NkeMGKFqt912m423b9+ekv0h9fzv1TNnzrTxhg0bVO34449XuV8H0sUdi3rTTTep2oEDB2z80Ucfpb0X7sQFAAAAAAAAgAhjERcAAAAAAAAAIoxFXAAAAAAAAACIsMjNxK1bt66NZ8yYoWr+vJR082f39OvXz8Y7d+5UtTFjxth4/fr1qrZ161YbL1u2LJUt4ggVK1bMxmeeeaaqvf766zb2573Fs3z5cpUPGTLExmPHjlW1zz77zMbu8SUiMnjw4IT3iSxNmzZVeaVKlWycqTNx/flip556qo0rVKigasaYHOkJ0eD/+y9SpEhInSAnnHPOOSrv0qWLjZs0aaJq7vxCX+/evVX+008/2dj9fQER/Tn4xRdfJN4sQlW1alUbuzMhRUQ6d+5s46JFi6qa/xny448/2tif91+tWjUbd+jQQdWee+45Gy9dujTRthGyXbt22Xj16tUhdoKocb+TtGrVKsRO4uvWrZvKX3rpJRu737mQOfwZuMzERVjc3zIqWLCgqs2ePdvG48aNS3sv3IkLAAAAAAAAABHGIi4AAAAAAAAARFjkximsWbPGxlu2bFG1VIxT8B8H/PXXX1X+5z//2cb79+9Xtddee+2I949oeeGFF2zcqVOnlGzTH8tQvHhxG3/88ceq5j7+X7t27ZTsPy/zH6P6/PPPQ+okdfxRHn/9619t7D7qLMJjq3lB8+bNbdyzZ8+Yr/OPhUsvvdTGP//8c+obQ1pcddVVNn766adVrWzZsjb2H4OfNWuWyo899lgbP/bYYzH352/HfV/Hjh3/uGHkGPea+NFHH1U197g5+uijE96mPw7qwgsvtLH/6KB7jnGPxd/LkRlKlSpl4zp16oTYCaJm+vTpNo43TmHjxo0qd8cZ+OPB/LGFrnPPPVfl/sgg5B2MisPvOf/881V+33332dhf0/nll1+S2oe/nZo1a9p45cqVquaPKks37sQFAAAAAAAAgAhjERcAAAAAAAAAIoxFXAAAAAAAAACIsMjNxHVnVvTp00fV3Jl+33zzjao988wzMbe5YMECG7do0ULVdu3apfIaNWrY+NZbb02gY2SS+vXrq/ySSy6xcbyZO/4s23fffVflQ4cOtfFPP/2kau6xunXrVlVr1qxZQvtHYvx5W7nBqFGjYtb8+YXIfRo3bqzy0aNH2zjenHh/7unq1atT2xhSpkCB/16KnXXWWar24osv2rhYsWKq9sknn9h4wIABqjZ79myVFy5c2Mbjxo1TtZYtW8bsbd68eTFrCNfll19u47/85S9JbcOf6eZfI//44482PuOMM5LaBzKHe44pX758wu87++yzVe7OS+azJ3d4/vnnbTxp0qSYrztw4IDKN2zYkNT+SpQoofKFCxfa+MQTT4z5Pr83PsMyXxAEKi9SpEhInSBKRo4cqfJKlSrZuHr16qrmXxMn6t5771V5mTJlbOz+Ro2IyLfffpvUPpKV+1Y8AAAAAAAAACAXYREXAAAAAAAAACIscuMUXP4jETNmzLDxjh07VK1OnTo2vv7661XNfdTdH5/gW7RokY1vuOGGxJtFZNWtW9fG06dPVzX3cR3/cY0PPvjAxp06dVK1Jk2aqLxfv3429h9/37Rpk439W+0PHTpkY3e0g4jImWeeaeP58+cLfl/t2rVtXK5cuRA7SY94j8z7xzNyn2uuuUbl8R4jnDVrlo3//ve/p6slpFiXLl1sHG98iv/f+1VXXWXj7du3x92H+9p44xPWrl2r8ldffTXudhGe9u3bJ/S6VatWqfyrr76ycd++fVXNHZ/gq1atWuLNISO548BeeeUVVevfv3/M9/m1X3/91cbDhw9PRWsI2cGDB20c7zyRKhdeeKHKjznmmITe53+G7du3L2U9IRr8sVNz584NqROEaffu3Sp313GOZOSGu25UoUIFVXPXbcIe68GduAAAAAAAAAAQYSziAgAAAAAAAECEsYgLAAAAAAAAABEW6Zm4vngz37Zt2xaz9te//tXGb775pqq5sy2QO1SuXFnlffr0sbE/X3Tz5s02Xr9+vaq5swB37typalOmTImbJ6No0aIqv/POO23cuXPnI95+btWqVSsb+/8MM5U72/fUU0+N+bp169blRDvIQWXLllX5ddddp3L3M8udOygiMnDgwPQ1hpQZMGCAyu+9914b+7PZn3vuORu7s9dF/ngOruu+++5L6HW9evVSuTvTHdHiXtv6v+Hw4Ycf2njFihWqtnHjxqT2lxtnziM2/zwVbyYukAodO3a0sXt+E0n8+v6BBx5IaU/IGe7MZRG9ruN/dz/99NNzpCdEj/u5VKtWLVVbsmSJjf3fIIrnqKOOUrn7WwHFihVTNXf+8vjx4xPeRzpwJy4AAAAAAAAARBiLuAAAAAAAAAAQYRk1TiEe9zGf+vXrq1qTJk1s3Lx5c1VzHzlD5ipcuLCNhw4dqmru4/Y7duxQtW7dutl43rx5qhb2o/nly5cPdf+ZokqVKjFrixYtysFOUsc9hv1HWL/77jsb+8czMlPFihVt/Pbbbyf8vmHDhql85syZqWoJKeY+4umOTxAR2b9/v42nTZumau5jXXv27Im5/SJFiqi8ZcuWKnc/T4wxquaO4Zg8eXLMfSBafvrpJxvnxKPujRo1Svs+EF358v33vh9G0SEZ/mi4u+++W+VnnHGGjQsWLJjwdhcsWGDjAwcOJNkdwuSPB/v0009tfOmll+Z0O4iIU045ReXumBV/BMctt9xi4+yMAnviiSdU3r59exu711kiIn/6058S3m66cScuAAAAAAAAAEQYi7gAAAAAAAAAEGEs4gIAAAAAAABAhOWambi7du2ysTsvQ0Rk/vz5Nn7xxRdVzZ8h6M5FffbZZ1UtCIIj7hPpUa9ePRu7M3B9bdq0UfnHH3+ctp4Qvq+++irsFqwSJUqo/KKLLrJxly5dVM2fZ+kaMGCAjf0ZUshM7rFQu3btuK/96KOPbPz000+nrSccmVKlSqn85ptvtrF/LeHOwW3btm3C+3DnB44ZM0bV/N8GcI0fP17lQ4YMSXifyHy9evWy8VFHHZXw+2rVqhWzNmfOHJV//vnn2W8MkebOweX7UN7jzu7v2rWrqvm/NxNL48aNVZ6d42j79u029mfpvv/++zaONzseQPTVrFnTxhMnTlS1smXL2tj/XZDsrOn07t3bxtdee23M1w0aNCjhbeY07sQFAAAAAAAAgAhjERcAAAAAAAAAIizXjFNwrVy5UuXubdKjR49WNf+REDf3HzP7+9//buP169cfaZtIoSeeeMLGxhhVc2+vj9r4hHz5/vv3KO6jakiN0qVLJ/W+OnXq2Ng/ntzHxk4++WRVK1SokI07d+6sau6/axH9yNcXX3yhavv27bNxgQL6NP3111/H7R3R5z8y/8gjj8R87ezZs1V+zTXX2Hjbtm2pbQwp454LRPQjYD738fbjjjtO1bp3727j1q1bq5r7yFnx4sVVzX9M1c1ff/11VXPHUSEzFStWTOXVq1e38YMPPqhq8UZO+Z9T8a5LfvrpJxu7x6mIyG+//Ra7WQCR536+iIi88847Ni5fvnxOtyOffvqpjUeOHJnj+0d0lClTJuwWcITc77b+SMGXXnrJxvGuSRo1aqRq99xzj43ddSGR/10PaN++vY397/nuet8LL7zw+/8PRAB34gIAAAAAAABAhLGICwAAAAAAAAARxiIuAAAAAAAAAERYrpyJ65s4caKNly9frmr+zIwLLrjAxg8//LCqVahQwcaDBg1StXXr1h1xn0jcpZdeqvK6deva2J8F6M5xihp3tovf94IFC3K6nYzkzpb1/xmOGDHCxvfee2/C26xdu7aN/Vk5Bw8etPHu3btVbfHixTZ++eWXVW3evHkqd+cz//zzz6q2du1aGxctWlTVli5dGrd3RFPFihVt/Pbbbyf8vu+//17l/rGCaNq/f7/KN23aZONjjz1W1X744Qcb++eweNyZpNu3b1e1E044QeWbN2+28bvvvpvwPhAdBQsWVHm9evVs7J9T3H//7mekiD5uPv/8c1W76KKLVO7P2nW5M+3atWunak8//bSN/f8WAGQe91rYvy5OVHZmbvvc730XX3yxqn3wwQdJ9YPM5P8+ADJPx44dbTxq1ChVc6+D/XPEihUrbHzWWWepmpu3adNG1U466SSVu9dI7vW5iMh1110Xt/eo4E5cAAAAAAAAAIgwFnEBAAAAAAAAIMJYxAUAAAAAAACACMsTM3FdCxcuVHmHDh1Uftlll9l49OjRqnbjjTfauFKlSqrWokWLVLWIBPhzQgsVKmTjjRs3qtqbb76ZIz3FUrhwYRv3798/5utmzJih8nvuuSddLeUqN998s41Xr16taueee25S21yzZo2NJ02apGpLliyx8dy5c5Pavu+GG25QuTsz05+JiszUt29fG2dnDtwjjzySjnaQZr/++qvK27Zta+P33ntP1UqXLm3jlStXqtrkyZNt/Morr6jaL7/8YuOxY8eqmj8T168jM7jXNv682gkTJsR839/+9jcb+9cWn332mY3dY+/3XluzZs2Y+3A/pwYPHqxq8T5D9+3bF3ObiC53nukffYadf/75Nh4+fHjaekL6+N+XmzZtauMuXbqo2rRp02y8d+/epPd5/fXX27hnz55JbweZb+bMmTb2fwcHmeeqq65SubvGduDAAVVzr5+vvvpqVdu6dauNH3/8cVVr0qSJjf15uf4cb3fubtmyZVXtxx9/tLF73hP532v0MHEnLgAAAAAAAABEGIu4AAAAAAAAABBheW6cgs9/5PG1116z8ahRo1StQIH//uNyHxUS0bdbz5o1K3UNItv8R/XWr1+fo/t3xyeIiPTr18/Gffr0UbW1a9fa2H8sYOfOnWnoLnd79NFHw24hKRdccEHM2ttvv52DnSBV6tatq/KWLVsm9D738XkRkWXLlqWsJ4Tniy++sLH7GPqRcK9D3MfIRP73cWfGsmSGggULqtwdi+BfP7g++OADlQ8bNszG/nWue/y9//77qlarVi2V79+/38ZDhgxRNXfUQps2bVRtzJgxNv7nP/+pau7ntPtopG/BggUxa8h57jnFfRT197Rr187G1atXV7XFixentjHkCHdc2aBBg9KyD3fkHOMU8jZ3JI/P/5ysUKGCjf2xeogGdySpiP73O3DgQFXzx5nG4p8jXnjhBRs3atQo4d78UQvuKI8ojU/wcScuAAAAAAAAAEQYi7gAAAAAAAAAEGEs4gIAAAAAAABAhOW5mbi1a9dW+ZVXXqnys88+28buDFyfP9Ppk08+SUF3SIV33nknx/fpzr/059ZdddVVNvbnXV5xxRXpbQwZb+LEiWG3gCR8+OGHKj/mmGNivnbu3Lk2vvbaa9PVEnKZokWL2tifgevPrBw7dmyO9ITsy58/v40HDBigar1797bxrl27VO3uu++2sf/v152De9ZZZ6na8OHDbVyvXj1VW758ucp79OhhY3dOnIhIiRIlbHzuueeqWufOnW3cunVrVZs+fbrE8uOPP9r41FNPjfk65LwRI0bY2J9vGM8NN9yg8ttuuy1lPSF3ufDCC8NuARFx8ODBmDV/hqn/WzSIHn/9Y8KECTZ2P/ezo2zZsip35/T7OnXqpPKFCxfGfK37e0VRxp24AAAAAAAAABBhLOICAAAAAAAAQITlynEKVapUUfktt9xi43bt2qna8ccfn/B2f/vtNxuvX79e1fxHGZFe/qMUbt62bVtVu/XWW1O+/9tvv13l999/v41LliypamPGjLFxt27dUt4LgOgpU6aMyuN9Rjz33HM23rlzZ9p6Qu4ybdq0sFtACriPm7vjE0REdu/ebWP/EXZ3ZEvDhg1VrXv37ja++OKLVc0dw/HQQw+p2ujRo1Ue7zHH7du323jq1Kmq5ub+Y4xXX311zG3611aIjqVLl4bdAlKsYMGCKm/ZsqWNZ8yYoWp79uxJ+f7d85SIyNNPP53yfSAzuY/f++eeqlWrqtwd0XLzzTentzEkJVX/bbtrLO3bt1c1d8TTypUrVW3cuHEp2X+UcCcuAAAAAAAAAEQYi7gAAAAAAAAAEGEs4gIAAAAAAABAhGXsTFx/lq07c8udgSsiUrFixaT2MW/ePJUPGjTIxu+8805S20RqBEEQM/ePjWeeecbGL7/8sqpt2bLFxv5Mua5du9q4Tp06qnbyySerfM2aNTb25xS68y6BRLgznitXrqxqc+fOzel2kCB3nmS+fIn/HemcOXPS0Q5yuQsvvDDsFpACDzzwQMxa/vz5bdynTx9V69+/v43POOOMhPfnvm/w4MGq5v72Q6q88cYbcXNkhmHDhtm4Z8+eqnb66afHfJ//uxTudvy5hUi/xo0b2/i+++5TtRYtWtj41FNPVbV487HjKV26tI1btWqlak888YTKixUrFnM77kzevXv3JtULMpM7/11E5KSTTlL5HXfckZPtIETuzOMePXqo2saNG23crFmzHOspLNyJCwAAAAAAAAARxiIuAAAAAAAAAERYpMcplCtXTuXVq1e38fDhw1WtatWqSe3jiy++UPljjz1m48mTJ6vaoUOHktoHcpb7+KGIvvX+iiuuULXt27fbuFKlSgnvw3/8eebMmTaO92gkkAh3PEh2HstHzqpbt67KmzdvbmP/82L//v02fvbZZ1Xt559/TkN3yO1OO+20sFtACmzYsMHGxx57rKoVLlzYxv5YJ9f777+v8k8++cTGkyZNUrVVq1bZOB3jE5D7LVq0SOXxzkV8d4oW9/tzzZo1Y77urrvuUvmOHTuS2p87ouHMM89UNX80nmvWrFkqf/75523sfudC3uMfN+71NXKXChUqqPwvf/mLjf3jYOTIkTZeu3ZtehuLAFYHAAAAAAAAACDCWMQFAAAAAAAAgAhjERcAAAAAAAAAIiz0mbilS5dW+QsvvGBjf95gsvPf3Pmljz/+uKpNmzZN5Xv27ElqH8hZn3/+ucq/+uorG5999tkx33f88cer3J+77NqyZYuNx44dq2q33nprQn0CR6pRo0Yqf+WVV8JpBP+jVKlSKvfPL65169bZuHfv3mnrCXnHp59+amN/djZzKDPH+eefb+O2bduqmjtDcuPGjar28ssv23jr1q2qxoxApJM7e1BE5LLLLgupE6RLjx490r4P/5z27rvv2tj/nrV3796094PMUKJECZW3adPGxhMnTszpdpBG06dPV7k7I/f1119XtQcffDBHeooK7sQFAAAAAAAAgAhjERcAAAAAAAAAIixHximcc845Ku/Tp4+NGzRooGonnXRSUvvYvXu3jZ955hlVe/jhh228a9eupLaPaFm7dq3K27VrZ+Mbb7xR1fr165fQNp9++mmVP//88zZesWJFdlsEkmaMCbsFABG3cOFCGy9fvlzV/PFTp59+uo03bdqU3saQLTt27LDxa6+9pmp+DkTB4sWLVb5kyRKVV6tWLSfbQTZce+21Nu7Zs6eqXXPNNUe8/ZUrV6rc/X7ujgAS+d+xHO5nGvAfHTp0UPm+fftU7p9/kHuMHj1a5QMGDLDx5MmTc7qdSOFOXAAAAAAAAACIMBZxAQAAAAAAACDCWMQFAAAAAAAAgAjLkZm4l19+edw8Fn/m0nvvvWfjgwcPqtrjjz9u419//TW7LSLDrV+/3sb9+/dXNT8HouaDDz5Qefv27UPqBNmxdOlSlc+ZM8fGjRs3zul2kIe5s/9FREaNGqXyQYMG2difg+hfawFAPKtXr1Z5rVq1QuoE2bVgwQIb33zzzar25Zdf2njgwIGqdswxx9h40qRJqjZ9+nQb+3MqN2zYkHyzgIh88sknKvdnbu/Zsycn20EOGjx4cNw8L+NOXAAAAAAAAACIMBZxAQAAAH0N9YgAACAASURBVAAAACDCTBAEib/YmMRfjHT7OgiCs8JuIhEcN9ERBIEJu4dEcMxECucaJIPjJgeVKFFC5ePGjVN58+bNbTxhwgRV6969u4137dqVhu6yheMGyeC4QTI4bpAMjhtkG9/BkYSY5xruxAUAAAAAAACACGMRFwAAAAAAAAAijEVcAAAAAAAAAIiwAmE3AAAAgORt375d5R06dFD5oEGDbNyjRw9V69+/v40XL16c+uYAAAAApAR34gIAAAAAAABAhLGICwAAAAAAAAARxjgFAACAXMQfr9CzZ8/fjQEAAABkDu7EBQAAAAAAAIAIYxEXAAAAAAAAACKMRVwAAAAAAAAAiLDszsTdLCKr09EIsq1C2A1kA8dNNHDMIBkcN0gGxw2SwXGDZHDcIBkcN0gGxw2yi2MGyYh53JggCHKyEQAAAAAAAABANjBOAQAAAAAAAAAijEVcAAAAAAAAAIgwFnEBAAAAAAAAIMLyzCKuMeZ1Y8x6Y8x2Y8x3xpi/hN0Tos8YM8sYs9cYs/Pwn2Vh94To43yDZBljOhpjlhhjdhljVhpjzgu7J0SXMeYWY8w8Y8w+Y8wrYfeDzOBc0/znz2/GmGFh94XoMsYUNsa8ZIxZbYzZYYxZYIy5OOy+EH3GmIrGmPeNMVuNMRuMMcONMdn9cXXkQVwTI7uMMdWMMTOMMduMMSuMMZeH3VM65JlFXBEZLCIVgyAoISKtRWSgMaZ+yD0hM9wSBEHxw3+qhN0MMgLnG2SbMaaFiDwqIt1F5GgROV9Evg+1KUTdTyIyUEReDrsRZA7nmqa4iBwvIntE5K2Q20K0FRCRH0WkiYiUFJF+IjLOGFMxxJ6QGZ4TkY0icoKI1JWsY+jmUDtC5HFNjOw6/JdDk0XkPREpLSI3iMjrxpjKoTaWBnlmETcIgkVBEOz7T3r4z+khtgQgl+J8gyT9TUQeCoJgbhAEh4IgWBcEwbqwm0J0BUEwIQiCSSKyJexekLGukKwFlk/DbgTRFQTBriAI+gdBsOrw59N7IvKDiPAX1Pgjp4rIuCAI9gZBsEFEpopIjZB7QvRxTYzsqioiJ4rIk0EQ/BYEwQwR+UxEuobbVurlmUVcERFjzHPGmN0islRE1ovI+yG3hMww2Biz2RjzmTGmadjNIDNwvkF2GGPyi8hZInLs4cd/1h5+5LBo2L0ByNWuEZG/B0EQhN0IMocxppyIVBaRRWH3gsh7SkQ6GmOKGWNOEpGLJWshF/hdXBMjhYyI1Ay7iVTLU4u4QRDcLFm3458nIhNEZF/8dwDSV0ROE5GTRGSkiLxrjOGOSvwhzjfIpnIiUlBErpSsY6auiNSTrEdWASDljDEVJOvR5lfD7gWZwxhTUETGiMirQRAsDbsfRN4nknXn7XYRWSsi80RkUqgdIeq4JkYylknWk0V9jDEFjTEtJesap1i4baVenlrEFRE5fGv1bBE5WUR6hN0Poi0Igi+CINgRBMG+IAhelaxb8luF3RcyA+cbZMOew/93WBAE64Mg2CwiTwjnGwDp01VEZgdB8EPYjSAzGGPyichrIrJfRG4JuR1E3OHjZapk3cxwlIiUFZFjJGvWKRAL18TItiAIDohIWxG5REQ2iMidIjJOsv7yKFfJc4u4jgLCjEpkXyBZt+UD2cH5BnEFQbBVsi4y3EeaebwZQDp1E+7CRYKMMUZEXpKsu+SuOPyFGYintIiUF5Hhh2+I2SIio4XFOMTBNTGSFQTBv4IgaBIEQZkgCC6UrCeqvwy7r1TLE4u4xpjjjDEdjTHFjTH5jTEXikgnEfko7N4QXcaYUsaYC40xRYwxBYwxnSXrlzGZ44SYON/gCIwWkZ6Hj6FjROR2yfqFVeB3Hf5sKiIi+UUk/38+r8LuC9FnjDlXskZFvRV2L8gYz4tINRG5LAiCPX/0YuDwHZQ/iEiPw59XpSRrDve/wu0MGYBrYmSbMab24WvhYsaY3iJygoi8EnJbKZcnFnEl629uekjW3+hsFZGhInJbEATvhNoVoq6giAwUkU0isllEeopI2yAIvgu1K0Qd5xska4CIfCUi34nIEhH5RkQGhdoRoq6fZD12eLeIdDkcMzMOibhGRCYEQbAj7EYQfYfnJ98oWbMpNxhjdh7+0znk1hB97UTkIsn6PrVCRA5I1oIcEA/XxEhGV8n6QfGNInKBiLQIgiDX/S6N4cdoAQAAAAAAACC68sqduAAAAAAAAACQkVjEBQAAAAAAAIAIYxEXAAAAAAAAACKMRVwAAAAAAAAAiLAC2XmxMYZfQYuOzUEQHBt2E4nguImOIAhM2D0kgmMmUjjXIBkcN0gGxw2SwXGDZHDcIBkcN8g2voMjCTHPNdyJm7lWh90AgDyBcw2SwXGDZHDcIBkcN0gGxw2SwXEDICfEPNewiAsAAAAAAAAAEcYiLgAAAAAAAABEGIu4AAAAAAAAABBhLOICAAAAAAAAQISxiAsAAAAAAAAAEVYg7AYAAEBiKleubOOpU6eqWv78+W1coUKFHOsJAAAAAJB+3IkLAAAAAAAAABHGIi4AAAAAAAAARBiLuAAAAAAAAAAQYczEBQAgooYNG6byq666ysalS5dWtffeey9HegIAAADCdtppp9l48ODBqnb55ZfbuHbt2qq2dOnS9DYGpBF34gIAAAAAAABAhLGICwAAAAAAAAARlmvGKVSvXt3Gl156qardcMMNNv7qq69U7Ztvvom5zaeeekrl+/fvP5IWAQD4H+XKlbPxhAkTVK1hw4YqD4LAxgsXLlS166+/Pg3dAQAAAOE799xzVT516lQbb9q0SdWeffZZG//888/pbQzIQdyJCwAAAAAAAAARxiIuAAAAAAAAAEQYi7gAAAAAAAAAEGEZOxP3xhtvVPnQoUNtXLx48ZjvO/3001XesWPHmK/15+fOnDkzOy0CyAHuf+9XXXWVqu3du9fG9evXV7Wjjz7axp07d1a1WbNm2XjdunVJ9bVhwwaVT548WeXz5s1LarvIfJUrV1a5+/l1zjnnxH3vPffcY2P/GNqyZUsKukOUGGNs/MYbb6haq1atbOz+LoCIyNq1a9PbGIBcp2vXrjZu2bKlqtWtW9fGVapUibuduXPn2viyyy5TtW3bth1Ji4AcddRRKnev2U888URV+9Of/mTjVatWpbMtpMkll1yi8vHjx6t8xIgRNr7vvvtUbffu3elrDAgRd+ICAAAAAAAAQISxiAsAAAAAAAAAEWaCIEj8xcYk/uI0K126tMqXLFli4+OOOy4l+/j1119V7j6q/eGHH6ZkH0fg6yAIzgq7iURE6bjJ64IgMH/8qvBl55gZMmSIjXv37p2WflLh0KFDKl+8eLGN/cek3TwCj39xrkmxhg0bqnz27NkxX+s+Ti8i0qVLFxv7x03EcNykQLFixWy8bNkyVTvppJNsfMMNN6jaqFGj0ttY+nDcIBkcNwkqW7asjf3zhDv6wP8ONGfOnJjbbNq0qcrdx92XLl2qav7ol5Bx3ITIH31w7LHHxnzt1q1bbfznP/9Z1UaPHm1j/3OyQYMGNt6xY0dSff4Ojps0O+OMM2z87bffqtqnn36qcne0lP9dK0py43dwpF3Mcw134gIAAAAAAABAhLGICwAAAAAAAAARxiIuAAAAAAAAAERYgbAbSNYvv/yi8gcffNDGjz/+uKq5M+XWrFmjauXLl4+5j1KlSqn8oosusnEEZuIiF6hQoYKNixYtqmqdOnWycY8ePWJuY8qUKSrv3r17irrLDO3atUvqfVu2bLHxv/71r6S24c/eqlKlio3980e9evVUXrNmTRsPGjRI1dx+IjATFylQuXJlG//jH/9QNX/urcs/vidPnpzaxhBpu3fvtvHy5ctVzZ2JG2+WIJCoO++8U+WFChWycbVq1VStc+fOMbfjzkGtUaNGirpDKkydOtXGFStWVDX3NwYee+wxVfO/d7mqVq2q8i+//NLG7mefiMgDDzxg44ceeuiPG0bkudezvXr1UjX3e47PPzbifSd/5JFHbOzPVXavodatW6dq7jkM0VWkSBGVu/O6//3vf6tahw4dVB7lObjIOe7vZbm/YyUicu+996rcn8ft6tevn40HDx6cou5SjztxAQAAAAAAACDCWMQFAAAAAAAAgAjL2HEKvhEjRtj4pptuUrU6derYePv27UnvY/jw4Um/F3lX8+bNbew/Gu2OTChZsqSqBUGQ0PYbNmx4BN1lvgsvvNDG/qNZ3333Xcz3uY8pr1+/PuV9HX300Sr3HweK99hY69atbeyPy0Bm6tq1q439f/fvv/++jf3PL//RQORdzz77rMqbNm1qY/9Rd+A/mjRponL30We/dvnll6s83qiXeNcolSpVsvHixYtVzX8UGunVokULlbujncaNG6dq99xzT1L7cMdniIg89dRTNnYfTRXRI78Yp5A7NGvWzMbXX399wu/bt2+fyl9//fXf3aaIyN133x1zO+656JVXXlE1d3QaomvAgAEqP+ecc2zsfp6IHNlaDnIPf/3jySeftHGDBg1Uzb9eiXf94h6L/rpClEZWcicuAAAAAAAAAEQYi7gAAAAAAAAAEGEs4gIAAAAAAABAhOWambiugQMHqvy+++6zcd26dZPebqFChZJ+L3K3UaNG2bhWrVqqdvbZZye0jR07dqh8zJgxNv7qq69U7Y033rDx3r17E+4zN1q5cuXvxmG79NJLVR5vBq4/F+zFF19MS0/IOXPmzFG5+9mzatUqVbv99tttzAxcxPLll1/GrHXo0EHlffv2VXk65n4jZ51wwgkqd68DTjvttJjv8+ftH3XUUTb2Z95+/fXXKj/zzDOz3aeISL58/71HxN0fcl6BAvqr3ooVK2w8duzYtOxz/PjxNvZn4hYpUsTGJUqUUDVmXWaG/v37q7xPnz4xX/vqq6/aeNOmTao2dOhQlbt1//v6tGnTbFy2bNmY73OPPURb4cKFbdylSxdVmzVrlo3Xrl2bUy0h4tz/9v3vyu5vQ/jnmkmTJql88uTJNu7WrZuqtW/f3sb+3F13LXD//v2Jtp0W3IkLAAAAAAAAABHGIi4AAAAAAAAARFiuHKfgP0oxe/ZsG3/44Yeq5j/6Ho87puHKK69MsjtkojJlyqh88ODBKr/uuuts/Msvv6ia+3jiI488omoLFy608Z49e1RtzZo1yTWLHOOPWHnmmWds7D+eEU+jRo1UvmDBgiNrDKFo06aNjc855xxVC4LAxm+99Zaq5fWRKEiO+yi8fy5q3bq1yl944YUc6Qmp1bx5cxv7jw6ecsopR7z96tWrq3zz5s0qdx9dPPHEE1Vt9OjRNj755JNj7mPx4sVH0iKO0MyZM1Ver149G+/evTst+/RHRLnKlStn46uvvlrVRowYkZZ+kFr+iJSiRYvaePXq1armjjT8o7E+Z5xxho3vvfdeVTv22GNtvGvXLlVzxztwPZU57rrrLhsXL15c1dzjBvgPdwyCOz5BRK/xtWrVKuFtLl++XOXudZd/bePu89tvv014H+nAnbgAAAAAAAAAEGEs4gIAAAAAAABAhLGICwAAAAAAAAARlitn4nbu3FnlderUsXHNmjWT3q47Wxd5y/3336/y66+/XuXDhg2zsT/HZ+fOnelrDDnuz3/+s427du2qatdee23M9x04cEDlvXr1svHSpUtT0xxyVKlSpVR+3nnnJfS+rVu3qnzt2rVJ7f/WW29VebwZmb17905qH4gud86yz5+Ri8zkzgzMzgxcdyZp3759VW3u3Lk2XrZsWdztbNmyxcb++SbeHNxVq1bZ2P+cRM4KY0bo999/b+NFixapWo0aNWxcqVKlHOsJqeP/9sxFF11kY3/OtvtbIDfffLOqlSxZUuVPPPGEjS+55BJVc39vZNCgQar2/PPPJ9I2IqZly5Y2/uyzz1Rt/vz5Od0OMoD/+0Eud15uqmzfvl3l/u8GhIk7cQEAAAAAAAAgwljEBQAAAAAAAIAIy9hxClWrVlX5xIkTbXzGGWeoWoECqfl/85133knJdhAdxYoVs7H/yKH7COBtt92majNnzlT5tGnTbBzGo2tInwYNGqj8ww8/tHH+/PkT3o7/6POaNWts/NtvvyXZHcLk/3urX7++jfPl039HeujQIRt/8sknCe/j9ttvj1nr2bOnyitUqBDztXfeeaeN/ceg161bl3A/ANLHfbxURKRhw4YJvc/9PBHR1y/+Y6rJijc+wec+1hilxw+RM9zxUQcPHgyxE6TDggULVO6OaPHHKTRr1szGLVq0ULUnn3xS5eXLl4+5z7/97W82dkfYIXM0btxY5e7nW61atZLebtOmTW28adMmVfPHuSCzGWN+NxbRo+qKFCmiaqeffrrK3fGH7nc3EZENGzbYuFOnTqoWpe9L3IkLAAAAAAAAABHGIi4AAAAAAAAARBiLuAAAAAAAAAAQYRk7E7datWoqP/XUU22cqhm4Pnc2oT+LEJmpX79+NvZn4o4bN87G7hxUEebe5iUdOnRQeXbm4LoKFSqk8ilTpth43rx5qvbuu+/a2J33LSKycOHCpPaP1GvSpInKzzvvPBu7M3BF9MzKeDMi69atG3ObIiKtW7eO+d5du3bZeO3atapWpUoVG48fP17VOnbsaOPVq1fH3D6A9HJnV4vouf2+OXPm2NidFymS/BzcY445RuUXXXSRjc8///yEehERef/995PaP3KHwoUL29ifTejasWNHTrSDFNu3b5/Kt2/fHvO1J554oo3ffvttVfNnWrq/HfHSSy+p2qRJk7LdJ6KlS5cuKl+yZImNf/jhh5jvc+eXiog8/vjjKnc/t/xjs3fv3jZ+9tlnE+4V0VSjRg0b+781c8cdd9jYv5by59663O9AIv/7HSmquBMXAAAAAAAAACKMRVwAAAAAAAAAiLCMHafgP2J811132fjRRx9VtXiP8mTHCSeckJLtIDruueceG/u35b/xxhs2ZnxC3jVhwgSVu6Nczj77bFUrW7ZsUvs466yzYuYPPvigqj311FM2HjJkiKpt3Lgxqf0jcUcffbSN3TE+vp9++knlr732mo1XrFihapUrV7Zxnz59VK1NmzYqd0cx+GNe3EfMSpYsqWozZsyIWUNmch9F9T+/kJlGjhypcvczZdu2bap29dVX23jDhg0p2f9NN92k8gEDBsR87aJFi2zsjx1KVT/ITBUrVrSxO8rHN3Xq1IS36f63UKdOHVVr1KiRjd966y1VW7ZsWcL7QHJSNYbJHcMydOhQVfvxxx9Tsg+E57rrrlO5+xnmj0FwR9D534NuvPFGlU+bNs3GrVq1UrXRo0fbeOXKlaqWnfMPomHLli02dr+PiejvzvFGtYiI7N6928aLFy9OZYs5hjtxAQAAAAAAACDCWMQFAAAAAAAAgAhjERcAAAAAAAAAIixjZ+L6nnnmGRsvX75c1UqVKhXzfQUK6H8Ew4cPt3GJEiVS1B2i6ssvv7SxP5fUPRb27NmjatOnT09vY4iMOXPmqPySSy6xcfny5VXNndlWrlw5VWvXrp3K3dlQ/uweV758+u/a7rjjDhvXr19f1S644AIbHzp0KOY2kbzGjRvb+Mknn4z5uhdffFHlDz30kI39Y8Od/ebP89qxY4fKx40bZ+PevXurWqVKlWw8YsSImNv56KOPVC1V8+yQs5iDm/u8/fbbcfNUu+yyy1T+wAMPxHztwYMHVe6eY5iBm7cULlxY5SeffLLKzz333IS2439Off311zY+88wzVa106dI2PuWUU1TN/Xw744wzVO3aa69NqBckLn/+/Co/77zzbBzvetY3ZcoUlfvnI2S+GjVq2Nhfc/E/U1zuf//+7Nrx48fHfN+bb76pcvea3f0dnN/bLqLPPZ4aNmyoau7nkH8c+Nzfu2EmLgAAAAAAAAAg5VjEBQAAAAAAAIAIYxEXAAAAAAAAACIs18zEdX3wwQcJv9af3ePOUvJng9WtW9fGFSpUUDVmCkbHOeeco/JvvvnGxvv371e1iy++2Ma9evVStfvvv9/G/vwdfx9Lly5NrllktDVr1sTNXf55adasWTbu2bOnqjVo0CCh/Tdp0kTl7ozUIUOGJLQNZE/t2rUTep07A9fnzmIS+d/ziatNmzYq//jjj23sz4OaPXt2zO089dRTNvZn6SL3+de//hV2C8gAkyZNUnm8Ocv+NdLIkSPT0hNSq2jRoio/7rjjbOzPnXU/U5o1axZzm0WKFFG5O6cwO/z3lSxZMuZrX375ZRv7s1Q3b95s41WrViXVCxI3duxYlbu/+ZCdWe3Mdc/9jj/++Ji1eN+dFy1aZON+/folvf/nn3/exv/+97+T3g6iZ+7cuSqvWbNmwu99+OGHU91OjuNOXAAAAAAAAACIMBZxAQAAAAAAACDCcuU4hewoVKiQyv0RCq4DBw7Y+LfffktbT/hjJ5xwgsrfe+89G5cvX17Vbr/9dhu//vrrqvbLL7/YePjw4armjlMoXry4qpUuXTqbHQPamDFjbPzmm2+q2j//+U8bn3/++Qlv0x0Hg/QoVaqUjf1xPJMnT475PnccT8WKFVXN3c6dd96pau74BBGRypUr2/gf//hHwttxxykg91u5cmXYLSCi3McI8+XT93IcOnQo5vv8cxGiwx+Z0L9/fxtfdtllqla1atWk9rF9+3Yb79ixQ9UOHjyo8gIFYn+9HDVqlI1HjBihavPnz0+qN6TeiSeeqPLu3bvb+IorrlA1dyyC/+/w22+//d1tiOjRHsh71q1bF7Pmn2OStXbt2pRsB9FXq1YtG2fn2iZTcScuAAAAAAAAAEQYi7gAAAAAAAAAEGEs4gIAAAAAAABAhOX5mbgDBw5M+LUvvfSSjZmxEi5/5lKJEiVs3LdvX1Xz5+DGcuutt8asuTNKRUQWLlyY0DaBRPjz5L7++msbZ2cm7nfffZeynvDH3Dlwv5fH4s9mct9Xu3ZtVVuzZo3KixQpYuMffvhB1c477zwbb9u2LaFeAORu/m8/1KtXz8bxzkUi+rpo+fLlaegOqTBp0iSVt2jRwsb79u1TtSlTptjY/wxx57r771u1apWN/e9AS5cuVbk7u/37779XtTvuuMPGO3fuFETTBRdcoPKHHnoo5mv79etnY//3Rdq2bWtjfybu4sWLj6RFZAD3txr835HICU2aNLFxqubsIpr27NljY//aZtasWSrfv39/TrSUVtyJCwAAAAAAAAARxiIuAAAAAAAAAERY6OMUypQpo/LRo0fb+I033lA1P0/GCSecoPIbbrgh4fdOmDDhiPeP1HjmmWdU7j7K49f83OU+HlipUiVVW716tY3vueceVdu+fXvizSLy/PPCX//6Vxv7jwmOGzcu5fvPnz+/yuvUqZPQ+/wxDHPnzk1ZT/h97uOmffr0UbU2bdrYuGHDhqpWt25dGx999NExt9+tWzeV+4+fbd682cb9+/dXtXXr1sXcLvKWwoULh90CQlSsWDEbd+nSRdXcR+19/nX2mDFjbOw/nojoaNmypcrdMQnt2rVTtQULFiS1jwIF/vuV8dFHH1W1k046SeUbN260cYcOHVSNEQrR1bRpUxvH++7UunVrlbsj544//nhVe+CBB2Juxx3RgdzJHdGT6MixI1GwYEGV33TTTTZ+7bXX0r5/5JyqVauq/Prrr7fxpk2bVO35559XeW4493AnLgAAAAAAAABEGIu4AAAAAAAAABBhLOICAAAAAAAAQISFPhPXn7lz2WWX2bhy5cqq9tNPP9nYn/23YsUKG9evX1/V3O3cddddqlaiRImYvT3++OMx949wDR48WOUHDhywcb169VStefPmMbdzzDHH2HjKlCmq1rt3bxu7xxdyB3du19SpU1WtVq1aNnaPkVQqV66cje+44w5Va9asWULbWLJkicpnz5595I0hLvdcs3v3blVz51B+9tlnqpbsLLAdO3ao3J3J/MEHHyS1TeR+rVq1UvmwYcNC6gQ5wZ+z/eKLL9r4yiuvjPm+22+/XeXDhw9XOXNwM4P/+fLrr7/aeOHChUlts0iRIip/6623bHzJJZeo2r59+1TesWNHG8+fPz+p/SPnufOyS5YsqWoff/yxjd977z1Vc+eQXnrpparmbsef8e/PrUTus3jxYhuvX79e1dx57f7M0uxwjz9/OxUrVrTxNddck/Q+EA3u+WTatGmq5s5m79u3r6qNHz8+vY2FgDtxAQAAAAAAACDCWMQFAAAAAAAAgAgLfZyC/4jfqaeeauNGjRqp2qxZs2y8atUqVXNv1z/vvPNUzX/MzOU/grR06VIbP/jgg6q2d+/emNtBuIYOHRp2C8gwTz31lI3d8Qk+95wkIrJs2TIb79mzJ+b7ihYtqnJ/lIs7QiHeOcp//Mx9vL5Xr14x34f0+Prrr23cqVMnVXP/nTZt2jThbb766qs2/ve//61q33zzjcrdRxqRt/z8888qX7RokY1r1KiR0+0gQtzHCEXij1BYuXKljf2RZshM3333ncrr1q1r45EjR6pamTJlbPztt9+q2vfff2/jPn36qFqVKlVs/MUXX6hajx49VL5gwYJE2kbEuONT/O/Hbu4+vi4i0rZtWxs//fTTqrZ161Ybjxo1StWO5BF6ZAZ3hMLDDz+sav7YSteYMWNsfNppp6lanTp1VH7vvffa2F+radmypY03b96cQMeIsiFDhtjYv+554403bBzv2MotuBMXAAAAAAAAACKMRVwAAAAAAAAAiDAWcQEAAAAAAAAgwkKfiTt37lyVf/755zZ+7bXXVO25556zccWKFVXNzxPlzuoREalevXpS2wGQWT766CMbd+jQIebr5s+fr3J3Rum2bdtivq9kyZIqr1evXnZbFBE9A1dE5PLLL7cx81HDNWXKlLg5kEr79+9Xebw5/S1atFC5//sDyHxVq1a18Z133hnzdf681IsvvjhtPSEc7rEgIjJgwAAb9+7dW9Xy5fvvHhok7QAAA+lJREFU/TsXXXRRzG2+8847KnePsalTpybVJ6LtuOOOi1nbtGmTjadPn65q/m/RuLp3727jd9999wi6Q6Z79tlnY9b8GabDhw+P+Vr/e5E7233gwIGq5l83IbM0b95c5V26dLGx/7s048ePz5GeooI7cQEAAAAAAAAgwljEBQAAAAAAAIAIC32cgs99XKdw4cKqVrx48Zjvcx9V7tSpU8zX+Y8/+48cAsgb3MfBxo4dq2odO3aM+b5kxyLEc/DgQZU/9dRTNn777bdV7Ysvvkj5/gFkngULFti4fv36qhbvegm5w/3332/jq666Kubr/FEaq1evTltPiAb32HBjIJ4lS5bErF155ZU2Nsao2i+//GJj/5H5f/7znynqDrmNe6zEG7WAvMUdkfrmm2/GfF23bt1UPnny5HS1FEnciQsAAAAAAAAAEcYiLgAAAAAAAABEGIu4AAAAAAAAABBhkZuJ69q3b5/KH3vssYTed/XVV6ejHQC5yKpVq2zcvXt3VXvnnXds3KxZM1X77rvvbNy6deuY21+6dGnc/c+YMSPma91ZlwDwewYNGmTjmjVrqtq4ceNyuh2kWY0aNVReokSJmK8dOXKkjd3PGgCI5dVXX7VxoUKFVM2drTxv3jxVc6+Zn3zyyTR1ByA3Klq0qMrd38cqWbKkqrm/EzNx4sT0NhZx3IkLAAAAAAAAABHGIi4AAAAAAAAARJgJgiDxFxuT+IuRbl8HQXBW2E0kguMmOoIgMGH3kAiOmUjhXINkcNwgGRw3MTz66KMqdx85XL16taq1atXKxsuWLUtvY9HAcYNkcNwgGRw3yDa+g/++Hj16qHz48OE2njNnjqo1b97cxv7Y1Vwq5rmGO3EBAAAAAAAAIMJYxAUAAAAAAACACGMRFwAAAAAAAAAirEDYDQAAAACI7cMPP1S5OxP3jjvuULU8MgcXAABkmAYNGtj43nvvVbWBAwfa+MUXX1S1PDIHNyHciQsAAAAAAAAAEcYiLgAAAAAAAABEGOMUAAAAgAj76KOPVF6gAJfwAAAgs3z55Zc2PuWUU0LsJHNxJy4AAAAAAAAARBiLuAAAAAAAAAAQYSziAgAAAAAAAECEZXeg1mYRWZ2ORpBtFcJuIBs4bqKBYwbJ4LhBMjhukAyOGySD4wbJ4LhBMjhukF0cM0hGzOPGBEGQk40AAAAAAAAAALKBcQoAAAAAAAAAEGEs4gIAAAAAAABAhLGICwAAAAAAAAARxiIuAAAAAAAAAEQYi7gAAAAAAAAAEGEs4gIAAAAAAABAhLGICwAAAAAAAAARxiIuAAAAAAAAAEQYi7gAAAAAAAAAEGH/DyO8YKtWba0ZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1800x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "RKoh5Cf70UYu",
        "outputId": "9051bc95-cdfe-4266-ebd5-7111e2c25218"
      },
      "source": [
        "visualize(mnist_data_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctjRsETiO1qO"
      },
      "source": [
        "## Partitioning the Data (IID and non-IID)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_v8lyrgO5dD"
      },
      "source": [
        "def iid_partition(dataset, clients):\n",
        "  \"\"\"\n",
        "  I.I.D paritioning of data over clients\n",
        "  Shuffle the data\n",
        "  Split it between clients\n",
        "  \n",
        "  params:\n",
        "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
        "    - clients (int): Number of Clients to split the data between\n",
        "\n",
        "  returns:\n",
        "    - Dictionary of image indexes for each client\n",
        "  \"\"\"\n",
        "\n",
        "  num_items_per_client = int(len(dataset)/clients)\n",
        "  client_dict = {}\n",
        "  image_idxs = [i for i in range(len(dataset))]\n",
        "\n",
        "  for i in range(clients):\n",
        "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
        "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
        "\n",
        "  return client_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zMdliGMQoSl"
      },
      "source": [
        "def non_iid_partition(dataset, clients, total_shards, shards_size, num_shards_per_client):\n",
        "  \"\"\"\n",
        "  non I.I.D parititioning of data over clients\n",
        "  Sort the data by the digit label\n",
        "  Divide the data into N shards of size S\n",
        "  Each of the clients will get X shards\n",
        "\n",
        "  params:\n",
        "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
        "    - clients (int): Number of Clients to split the data between\n",
        "    - total_shards (int): Number of shards to partition the data in\n",
        "    - shards_size (int): Size of each shard \n",
        "    - num_shards_per_client (int): Number of shards of size shards_size that each client receives\n",
        "\n",
        "  returns:\n",
        "    - Dictionary of image indexes for each client\n",
        "  \"\"\"\n",
        "  \n",
        "  shard_idxs = [i for i in range(total_shards)]\n",
        "  client_dict = {i: np.array([], dtype='int64') for i in range(clients)}\n",
        "  idxs = np.arange(len(dataset))\n",
        "  data_labels = dataset.targets.numpy()\n",
        "\n",
        "  # sort the labels\n",
        "  label_idxs = np.vstack((idxs, data_labels))\n",
        "  label_idxs = label_idxs[:, label_idxs[1,:].argsort()]\n",
        "  idxs = label_idxs[0,:]\n",
        "\n",
        "  # divide the data into total_shards of size shards_size\n",
        "  # assign num_shards_per_client to each client\n",
        "  for i in range(clients):\n",
        "    rand_set = set(np.random.choice(shard_idxs, num_shards_per_client, replace=False))\n",
        "    shard_idxs = list(set(shard_idxs) - rand_set)\n",
        "\n",
        "    for rand in rand_set:\n",
        "      client_dict[i] = np.concatenate((client_dict[i], idxs[rand*shards_size:(rand+1)*shards_size]), axis=0)\n",
        "  \n",
        "  return client_dict\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTfxv8kFoGAy"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvoDNFKbZST5"
      },
      "source": [
        "class MNIST_2NN(nn.Module):\n",
        "  \"\"\"\n",
        "  A simple multilayer-perceptron with 2-hidden layers with 200 units each\n",
        "  using ReLu activations\n",
        "\n",
        "  Total Expected Params: 199,210\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(MNIST_2NN, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(28*28, 200)\n",
        "    self.fc2 = nn.Linear(200, 200)\n",
        "    self.fc3 = nn.Linear(200, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    out = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut1hZ8x3qYPZ"
      },
      "source": [
        "class MNIST_CNN(nn.Module):\n",
        "  \"\"\"\n",
        "  CNN with two 5x5 convolution lauers(the first with 32 channels, second with 64,\n",
        "  each followed with 2x2 max pooling), a fully connected layer with 512 uunits and \n",
        "  ReLu activation, and the final Softmax output layer\n",
        "\n",
        "  Total Expected Params: 1,663,370\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(MNIST_CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "    \n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.out = nn.Linear(512, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.out(x)\n",
        "    out = F.log_softmax(x, dim=1)\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVv4HA9HuLtr"
      },
      "source": [
        "### Print Model Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5oTH710sJEt",
        "outputId": "77e285d7-d060-455a-ab08-88807a77b1b8"
      },
      "source": [
        "# mnist_mlp = MNIST_2NN()\n",
        "mnist_cnn = MNIST_CNN()\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "#   # mnist_mlp.cuda()\n",
        "#   mnist_cnn.cuda()\n",
        "\n",
        "# print(\"MNIST MLP SUMMARY\")\n",
        "# print(summary(mnist_mlp, (28,28)))\n",
        "\n",
        "mnist_cnn = module_modification.convert_batchnorm_modules(mnist_cnn)\n",
        "inspector = DPModelInspector()\n",
        "print(f\"Is the model valid? {inspector.validate(mnist_cnn)}\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "mnist_cnn = mnist_cnn.to(device)\n",
        "\n",
        "print(\"\\nMNIST CNN SUMMARY\")\n",
        "print(summary(mnist_cnn, (1, 28,28)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is the model valid? True\n",
            "\n",
            "MNIST CNN SUMMARY\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             832\n",
            "         MaxPool2d-2           [-1, 32, 12, 12]               0\n",
            "            Conv2d-3             [-1, 64, 8, 8]          51,264\n",
            "         MaxPool2d-4             [-1, 64, 4, 4]               0\n",
            "           Dropout-5             [-1, 64, 4, 4]               0\n",
            "            Linear-6                  [-1, 512]         524,800\n",
            "            Linear-7                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 582,026\n",
            "Trainable params: 582,026\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.23\n",
            "Params size (MB): 2.22\n",
            "Estimated Total Size (MB): 2.45\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf_8XEXa-gZ7"
      },
      "source": [
        "## Federated Averaging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-aNdQsQ-Kvp"
      },
      "source": [
        "### Local Training (Client Update)\n",
        "\n",
        "Local training for the model on client side"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBpWPYd8tD9Z"
      },
      "source": [
        "def accuracy(preds, labels):\n",
        "    return (preds == labels).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX6OsQyO-Gz7"
      },
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataset, idxs):\n",
        "      self.dataset = dataset\n",
        "      self.idxs = list(idxs)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.idxs)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "      image, label = self.dataset[self.idxs[item]]\n",
        "      return image, label\n",
        "\n",
        "class ClientUpdate(object):\n",
        "  def __init__(self, dataset, NUM_WORKERS, learning_rate, epochs, idxs, SAMPLE_RATE,N_ACCUMULATION_STEPS ,\n",
        "                                  EPSILON ,DELTA, MAX_GRAD_NORM):\n",
        "    self.train_loader = DataLoader(CustomDataset(dataset, idxs), num_workers=NUM_WORKERS,\n",
        "    batch_sampler=UniformWithReplacementSampler(\n",
        "        num_samples=len(CustomDataset(dataset, idxs)),\n",
        "        sample_rate=SAMPLE_RATE,\n",
        "    ),\n",
        "    )\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "  def train(self, model):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.5)\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=self.learning_rate)\n",
        "    privacy_engine = PrivacyEngine(\n",
        "    model,\n",
        "    sample_rate=SAMPLE_RATE * N_ACCUMULATION_STEPS,\n",
        "    epochs = EPOCHS,\n",
        "    target_epsilon = EPSILON,\n",
        "    target_delta = DELTA,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        "    )\n",
        "    privacy_engine.attach(optimizer)\n",
        "\n",
        "    print(f\"Using sigma={privacy_engine.noise_multiplier} and C={MAX_GRAD_NORM}\")\n",
        "\n",
        "    losses = []\n",
        "    top1_acc = []\n",
        "    e_loss = []\n",
        "    # for epoch in tqdm(range(self.epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
        "    for epoch in range(self.epochs):\n",
        "\n",
        "      train_loss = 0.0\n",
        "\n",
        "      model.train()\n",
        "      i=0\n",
        "      for data, labels in self.train_loader:\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "          data, labels = data.cuda(), labels.cuda()\n",
        "\n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        # make a forward pass\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
        "        target = labels.detach().cpu().numpy()\n",
        "        \n",
        "        # measure accuracy and record loss\n",
        "        acc = accuracy(preds, target)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        top1_acc.append(acc)\n",
        "        # do a backwards pass\n",
        "        loss.backward()\n",
        "        # perform a single optimization step\n",
        "        if ((i + 1) % N_ACCUMULATION_STEPS == 0) or ((i + 1) == len(self.train_loader)):\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            optimizer.virtual_step() # take a virtual step\n",
        "\n",
        "        # if i % 200 == 0:\n",
        "            # epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(DELTA)\n",
        "            # print(\n",
        "            #     f\"\\nTrain Epoch: {epoch} \\t\"\n",
        "        #         f\"Loss: {np.mean(losses):.6f} \"\n",
        "        #         f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
        "            #     f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
        "            # )\n",
        "        # update training loss\n",
        "        i=i+1\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "      # average losses\n",
        "      train_loss = train_loss/len(self.train_loader.dataset)\n",
        "      e_loss.append(train_loss)\n",
        "\n",
        "    total_loss = sum(e_loss)/len(e_loss)\n",
        "\n",
        "    return model.state_dict(), total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukgh1DVHE2Ds"
      },
      "source": [
        "### Server Side Training\n",
        "\n",
        "Following Algorithm 1 from the paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NF1e33BgpeL"
      },
      "source": [
        "def training(model, rounds, NUM_WORKERS, lr, ds, data_dict, C, K, E, plt_title, plt_color,SAMPLE_RATE,N_ACCUMULATION_STEPS,EPSILON,DELTA, MAX_GRAD_NORM,num_classes,classes_test):\n",
        "  \"\"\"\n",
        "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
        "  Specifically, this function is used for the server side training and weight update\n",
        "\n",
        "  Params:\n",
        "    - model:           PyTorch model to train\n",
        "    - rounds:          Number of communication rounds for the client update\n",
        "    - batch_size:      Batch size for client update training\n",
        "    - lr:              Learning rate used for client update training\n",
        "    - ds:              Dataset used for training\n",
        "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
        "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
        "    - K:               Total number of clients\n",
        "    - E:               Number of training passes each client makes over its local dataset per round\n",
        "    - tb_writer_name:  Directory name to save the tensorboard logs\n",
        "  Returns:\n",
        "    - model:           Trained model on the server\n",
        "  \"\"\"\n",
        "\n",
        "  # global model weights\n",
        "  global_weights = model.state_dict()\n",
        "\n",
        "  # training loss\n",
        "  train_loss = []\n",
        "  \n",
        "  # measure time\n",
        "  start = time.time()\n",
        "\n",
        "  for curr_round in range(1, rounds+1):\n",
        "    w, local_loss = [], []\n",
        "\n",
        "    m = max(int(C*K), 1)\n",
        "    \n",
        "    S_t = np.random.choice(range(K), m, replace=False)\n",
        "    for k in S_t:\n",
        "      local_update = ClientUpdate(dataset=ds, NUM_WORKERS=NUM_WORKERS, learning_rate=lr, epochs=E, idxs=data_dict[k],SAMPLE_RATE=SAMPLE_RATE,N_ACCUMULATION_STEPS = N_ACCUMULATION_STEPS,\n",
        "                                  EPSILON = EPSILON,DELTA = DELTA, MAX_GRAD_NORM = MAX_GRAD_NORM)\n",
        "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
        "\n",
        "      w.append(copy.deepcopy(weights))\n",
        "      local_loss.append(copy.deepcopy(loss))\n",
        "\n",
        "    # updating the global weights\n",
        "    weights_avg = copy.deepcopy(w[0])\n",
        "    for k in weights_avg.keys():\n",
        "      for i in range(1, len(w)):\n",
        "        weights_avg[k] += w[i][k]\n",
        "\n",
        "      #add DP noise:\n",
        "      # if weights_avg.requires_grad:\n",
        "      # weights_avg[k] = torch.div(weights_avg[k], len(w)) + torch.normal(\n",
        "      #             0,\n",
        "      #             0.5 * 0.8 /len(w),\n",
        "      #             weights_avg[k].shape,\n",
        "      #             device=weights_avg[k].device,\n",
        "      #         )\n",
        "      # else:\n",
        "      weights_avg[k] = torch.div(weights_avg[k], len(w))\n",
        "    global_weights = weights_avg\n",
        "    # move the updated weights to our model state dict\n",
        "    model.load_state_dict(global_weights)\n",
        "\n",
        "    # loss\n",
        "    loss_avg = sum(local_loss) / len(local_loss)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    testing(model, ds, 128, criterion, num_classes, classes_test, curr_round)\n",
        "    L = \"Round: \"  + str(curr_round) +\"   \"+\"Average Loss: \" + str(round(loss_avg, 3)) + \"\\n\"\n",
        "    with open(\"Round_avgloss_mnist_localDP_0.5.txt\", \"a+\") as file1:\n",
        "  \n",
        "      file1.writelines(L)\n",
        "    print('\\nRound: {}... \\tAverage Loss: {}\\n'.format(curr_round, round(loss_avg, 3)))\n",
        "    train_loss.append(loss_avg)\n",
        "\n",
        "  end = time.time()\n",
        "  fig, ax = plt.subplots()\n",
        "  x_axis = np.arange(1, rounds+1)\n",
        "  y_axis = np.array(train_loss)\n",
        "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
        "\n",
        "  ax.set(xlabel='Number of Rounds', ylabel='Train Loss',\n",
        "       title=plt_title)\n",
        "  ax.grid()\n",
        "  fig.savefig(plt_title+'.jpg', format='jpg')\n",
        "  print(\"Training Done!\")\n",
        "  print(\"Total time taken to Train: {}\".format(end-start))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUYyb4T-uXmF"
      },
      "source": [
        "## Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCcIZmO5uan9"
      },
      "source": [
        "def testing(model, dataset, bs, criterion, num_classes, classes, curr_round):\n",
        "  #test loss \n",
        "  test_loss = 0.0\n",
        "  correct_class = list(0. for i in range(num_classes))\n",
        "  total_class = list(0. for i in range(num_classes))\n",
        "\n",
        "  test_loader = DataLoader(dataset, batch_size=bs)\n",
        "  l = len(test_loader)\n",
        "  print(l)\n",
        "  model.eval()\n",
        "  i=0\n",
        "  for data, labels in test_loader:\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      data, labels = data.cuda(), labels.cuda()\n",
        "\n",
        "    output = model(data)\n",
        "    loss = criterion(output, labels)\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
        "\n",
        "    #test accuracy for each object class\n",
        "    # print(i)\n",
        "    for i in range(len(labels)):\n",
        "      label = labels.data[i]\n",
        "      # print(label)\n",
        "      correct_class[label] += correct[i].item()\n",
        "      # print(correct_class[label])\n",
        "      total_class[label] += 1\n",
        "      # print(total_class[label])\n",
        "    i=+1\n",
        "    \n",
        "  # avg test loss\n",
        "  test_loss = test_loss/len(test_loader.dataset)\n",
        "  print(len(test_loader.dataset))\n",
        "  print(\"Train Loss: {:.6f}\\n\".format(test_loss))\n",
        "\n",
        "  # print test accuracy\n",
        "  for i in range(10):\n",
        "    if total_class[i]>0:\n",
        "      print('Train Accuracy of %5s: %.3f%% (%2d/%2d)' % \n",
        "            (classes[i], 100.0 * correct_class[i] / total_class[i],\n",
        "            np.sum(correct_class[i]), np.sum(total_class[i])))\n",
        "    else:\n",
        "      print('Train Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "  model.train()\n",
        "  L = \"Round: \"  + str(curr_round) +\"   \"+\"Train Acc: \" + str(round(100. * np.sum(correct_class) / np.sum(total_class), 3)) + \"\\n\"\n",
        "  with open(\"Train_acc_mnist_localDP_0.5.txt\", \"a+\") as file1:\n",
        "\n",
        "      file1.writelines(L)\n",
        "  print('\\nFinal Train  Accuracy: {:.3f} ({}/{})'.format(\n",
        "        100. * np.sum(correct_class) / np.sum(total_class),\n",
        "        np.sum(correct_class), np.sum(total_class)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hO5oV6aXqeh"
      },
      "source": [
        "## MNIST CNN on IID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flSQv_P4zCfx"
      },
      "source": [
        "### Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZalcKZtEseA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "b4bb65ed-4c13-4fa5-d698-c67f2b64bfaa"
      },
      "source": [
        "# number of training rounds\n",
        "rounds = 10\n",
        "# client fraction\n",
        "C = 0.1\n",
        "# number of clients\n",
        "K = 100\n",
        "# number of training passes on local dataset for each roung\n",
        "E = 5\n",
        "# batch size\n",
        "# batch_size = 10\n",
        "# learning Rate\n",
        "# lr=0.01\n",
        "# data partition dictionary\n",
        "iid_dict = iid_partition(mnist_data_train, K)\n",
        "# load model\n",
        "mnist_cnn = MNIST_CNN()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  mnist_cnn.cuda()\n",
        "\n",
        "mnist_cnn_iid_trained = training(mnist_cnn, rounds, NUM_WORKERS, LR, mnist_data_train, iid_dict, C, K, E, \"MNIST CNN on IID Dataset\", \"orange\",SAMPLE_RATE,N_ACCUMULATION_STEPS,EPSILON,DELTA, MAX_GRAD_NORM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-8f5af130fc5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mmnist_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmnist_cnn_iid_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_WORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MNIST CNN on IID Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_ACCUMULATION_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPSILON\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDELTA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_GRAD_NORM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: training() missing 2 required positional arguments: 'num_classes' and 'classes_test'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNwC82przF6G"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB97BFs9we9w"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "testing(mnist_cnn_iid_trained, mnist_data_train, 128, criterion, num_classes, classes_test)\n",
        "print(len(mnist_data_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF8MdSIUYcnl"
      },
      "source": [
        "## MNIST CNN on Non IID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6wXX7JW11bx"
      },
      "source": [
        "### Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCD3kBCKYfBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c00161-a932-4578-ff01-73de1464244f"
      },
      "source": [
        "# number of training rounds\n",
        "rounds = 50\n",
        "# client fraction\n",
        "C = 0.1\n",
        "# number of clients\n",
        "K = 100\n",
        "# number of training passes on local dataset for each roung\n",
        "E = 5\n",
        "# batch size\n",
        "# batch_size = 10\n",
        "# learning Rate\n",
        "# lr=0.01\n",
        "# dict containing different type of data partition\n",
        "data_dict = non_iid_partition(mnist_data_train, 100, 200, 300, 2)\n",
        "# load model\n",
        "mnist_cnn = MNIST_CNN()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  mnist_cnn.cuda()\n",
        "\n",
        "# mnist_cnn_non_iid_trained = training(mnist_cnn, rounds, batch_size, lr, mnist_data_train, data_dict, C, K, E, \"MNIST CNN on Non-IID Dataset\", \"green\")\n",
        "mnist_cnn_non_iid_trained = training(mnist_cnn, rounds, NUM_WORKERS, LR, mnist_data_train, data_dict, C, K, E, \"MNIST CNN on Non-IID Dataset\", \"green\",SAMPLE_RATE,N_ACCUMULATION_STEPS,EPSILON,DELTA, MAX_GRAD_NORM,num_classes,classes_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.290973\n",
            "\n",
            "Train Accuracy of     0: 97.788% (5792/5923)\n",
            "Train Accuracy of     1: 38.238% (2578/6742)\n",
            "Train Accuracy of     2: 0.655% (39/5958)\n",
            "Train Accuracy of     3: 0.016% ( 1/6131)\n",
            "Train Accuracy of     4: 0.017% ( 1/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 10.152% (636/6265)\n",
            "Train Accuracy of     8: 0.017% ( 1/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 15.080 (9048.0/60000.0)\n",
            "\n",
            "Round: 1... \tAverage Loss: 1.986\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.289466\n",
            "\n",
            "Train Accuracy of     0: 11.126% (659/5923)\n",
            "Train Accuracy of     1: 43.414% (2927/6742)\n",
            "Train Accuracy of     2: 3.508% (209/5958)\n",
            "Train Accuracy of     3: 3.866% (237/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 99.266% (6219/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 17.085 (10251.0/60000.0)\n",
            "\n",
            "Round: 2... \tAverage Loss: 1.895\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.279021\n",
            "\n",
            "Train Accuracy of     0: 0.000% ( 0/5923)\n",
            "Train Accuracy of     1: 81.371% (5486/6742)\n",
            "Train Accuracy of     2: 49.261% (2935/5958)\n",
            "Train Accuracy of     3: 4.045% (248/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.553% (30/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 84.884% (5318/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 23.362 (14017.0/60000.0)\n",
            "\n",
            "Round: 3... \tAverage Loss: 1.959\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.261621\n",
            "\n",
            "Train Accuracy of     0: 2.279% (135/5923)\n",
            "Train Accuracy of     1: 37.407% (2522/6742)\n",
            "Train Accuracy of     2: 91.474% (5450/5958)\n",
            "Train Accuracy of     3: 33.061% (2027/6131)\n",
            "Train Accuracy of     4: 16.176% (945/5842)\n",
            "Train Accuracy of     5: 8.024% (435/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 61.596% (3859/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 25.622 (15373.0/60000.0)\n",
            "\n",
            "Round: 4... \tAverage Loss: 1.812\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.258980\n",
            "\n",
            "Train Accuracy of     0: 1.688% (100/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 4.280% (255/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 99.863% (5834/5842)\n",
            "Train Accuracy of     5: 9.463% (513/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 11.170 (6702.0/60000.0)\n",
            "\n",
            "Round: 5... \tAverage Loss: 1.823\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.241396\n",
            "\n",
            "Train Accuracy of     0: 46.969% (2782/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 99.966% (5840/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 14.370 (8622.0/60000.0)\n",
            "\n",
            "Round: 6... \tAverage Loss: 1.685\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.230044\n",
            "\n",
            "Train Accuracy of     0: 99.544% (5896/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 79.716% (4657/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.017% ( 1/5949)\n",
            "\n",
            "Final Train  Accuracy: 17.590 (10554.0/60000.0)\n",
            "\n",
            "Round: 7... \tAverage Loss: 1.617\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.215789\n",
            "\n",
            "Train Accuracy of     0: 98.768% (5850/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 2.854% (175/6131)\n",
            "Train Accuracy of     4: 85.519% (4996/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 1.250% (74/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 18.492 (11095.0/60000.0)\n",
            "\n",
            "Round: 8... \tAverage Loss: 1.536\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.247570\n",
            "\n",
            "Train Accuracy of     0: 100.000% (5923/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 0.171% (10/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 9.888 (5933.0/60000.0)\n",
            "\n",
            "Round: 9... \tAverage Loss: 1.513\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.219720\n",
            "\n",
            "Train Accuracy of     0: 99.932% (5919/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 9.183% (563/6131)\n",
            "Train Accuracy of     4: 24.427% (1427/5842)\n",
            "Train Accuracy of     5: 0.203% (11/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 13.200 (7920.0/60000.0)\n",
            "\n",
            "Round: 10... \tAverage Loss: 1.646\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.229968\n",
            "\n",
            "Train Accuracy of     0: 99.426% (5889/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 36.307% (2226/6131)\n",
            "Train Accuracy of     4: 31.137% (1819/5842)\n",
            "Train Accuracy of     5: 0.166% ( 9/5421)\n",
            "Train Accuracy of     6: 0.439% (26/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.393% (23/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 16.653 (9992.0/60000.0)\n",
            "\n",
            "Round: 11... \tAverage Loss: 1.45\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.199378\n",
            "\n",
            "Train Accuracy of     0: 97.923% (5800/5923)\n",
            "Train Accuracy of     1: 50.059% (3375/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 19.915% (1221/6131)\n",
            "Train Accuracy of     4: 69.856% (4081/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 0.017% ( 1/5918)\n",
            "Train Accuracy of     7: 51.476% (3225/6265)\n",
            "Train Accuracy of     8: 44.010% (2575/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 33.797 (20278.0/60000.0)\n",
            "\n",
            "Round: 12... \tAverage Loss: 1.489\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.158343\n",
            "\n",
            "Train Accuracy of     0: 99.730% (5907/5923)\n",
            "Train Accuracy of     1: 20.706% (1396/6742)\n",
            "Train Accuracy of     2: 0.017% ( 1/5958)\n",
            "Train Accuracy of     3: 4.094% (251/6131)\n",
            "Train Accuracy of     4: 82.369% (4812/5842)\n",
            "Train Accuracy of     5: 0.074% ( 4/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 7.127% (417/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 21.313 (12788.0/60000.0)\n",
            "\n",
            "Round: 13... \tAverage Loss: 1.441\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.150301\n",
            "\n",
            "Train Accuracy of     0: 99.206% (5876/5923)\n",
            "Train Accuracy of     1: 11.925% (804/6742)\n",
            "Train Accuracy of     2: 5.858% (349/5958)\n",
            "Train Accuracy of     3: 0.016% ( 1/6131)\n",
            "Train Accuracy of     4: 92.503% (5404/5842)\n",
            "Train Accuracy of     5: 3.320% (180/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 54.908% (3440/6265)\n",
            "Train Accuracy of     8: 18.903% (1106/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 28.600 (17160.0/60000.0)\n",
            "\n",
            "Round: 14... \tAverage Loss: 1.172\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.087472\n",
            "\n",
            "Train Accuracy of     0: 99.578% (5898/5923)\n",
            "Train Accuracy of     1: 45.580% (3073/6742)\n",
            "Train Accuracy of     2: 2.199% (131/5958)\n",
            "Train Accuracy of     3: 3.083% (189/6131)\n",
            "Train Accuracy of     4: 25.591% (1495/5842)\n",
            "Train Accuracy of     5: 0.756% (41/5421)\n",
            "Train Accuracy of     6: 64.312% (3806/5918)\n",
            "Train Accuracy of     7: 66.161% (4145/6265)\n",
            "Train Accuracy of     8: 2.341% (137/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 31.525 (18915.0/60000.0)\n",
            "\n",
            "Round: 15... \tAverage Loss: 1.343\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.177795\n",
            "\n",
            "Train Accuracy of     0: 46.345% (2745/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 7.148% (423/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 99.983% (5850/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 15.030 (9018.0/60000.0)\n",
            "\n",
            "Round: 16... \tAverage Loss: 1.184\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.099009\n",
            "\n",
            "Train Accuracy of     0: 99.916% (5918/5923)\n",
            "Train Accuracy of     1: 16.330% (1101/6742)\n",
            "Train Accuracy of     2: 0.352% (21/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 0.411% (24/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 25.211% (1492/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 15.724% (920/5851)\n",
            "Train Accuracy of     9: 0.134% ( 8/5949)\n",
            "\n",
            "Final Train  Accuracy: 15.807 (9484.0/60000.0)\n",
            "\n",
            "Round: 17... \tAverage Loss: 1.15\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.102492\n",
            "\n",
            "Train Accuracy of     0: 99.882% (5916/5923)\n",
            "Train Accuracy of     1: 0.445% (30/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 12.838% (750/5842)\n",
            "Train Accuracy of     5: 6.401% (347/5421)\n",
            "Train Accuracy of     6: 0.237% (14/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 33.652% (1969/5851)\n",
            "Train Accuracy of     9: 0.286% (17/5949)\n",
            "\n",
            "Final Train  Accuracy: 15.072 (9043.0/60000.0)\n",
            "\n",
            "Round: 18... \tAverage Loss: 1.3\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.086988\n",
            "\n",
            "Train Accuracy of     0: 99.730% (5907/5923)\n",
            "Train Accuracy of     1: 0.222% (15/6742)\n",
            "Train Accuracy of     2: 0.168% (10/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 2.653% (155/5842)\n",
            "Train Accuracy of     5: 3.892% (211/5421)\n",
            "Train Accuracy of     6: 1.369% (81/5918)\n",
            "Train Accuracy of     7: 0.144% ( 9/6265)\n",
            "Train Accuracy of     8: 52.982% (3100/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 15.813 (9488.0/60000.0)\n",
            "\n",
            "Round: 19... \tAverage Loss: 1.149\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.213225\n",
            "\n",
            "Train Accuracy of     0: 96.775% (5732/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 93.840% (5591/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 1.273% (69/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.016% ( 1/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 18.988 (11393.0/60000.0)\n",
            "\n",
            "Round: 20... \tAverage Loss: 1.007\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.104783\n",
            "\n",
            "Train Accuracy of     0: 99.865% (5915/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 35.415% (2110/5958)\n",
            "Train Accuracy of     3: 3.800% (233/6131)\n",
            "Train Accuracy of     4: 0.017% ( 1/5842)\n",
            "Train Accuracy of     5: 0.498% (27/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 49.545% (3104/6265)\n",
            "Train Accuracy of     8: 0.068% ( 4/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 18.990 (11394.0/60000.0)\n",
            "\n",
            "Round: 21... \tAverage Loss: 0.985\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.203736\n",
            "\n",
            "Train Accuracy of     0: 42.715% (2530/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 99.883% (5951/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.096% ( 6/6265)\n",
            "Train Accuracy of     8: 0.103% ( 6/5851)\n",
            "Train Accuracy of     9: 0.017% ( 1/5949)\n",
            "\n",
            "Final Train  Accuracy: 14.157 (8494.0/60000.0)\n",
            "\n",
            "Round: 22... \tAverage Loss: 1.103\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.069297\n",
            "\n",
            "Train Accuracy of     0: 82.543% (4889/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.117% ( 7/5958)\n",
            "Train Accuracy of     3: 0.718% (44/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 1.015% (55/5421)\n",
            "Train Accuracy of     6: 0.237% (14/5918)\n",
            "Train Accuracy of     7: 1.341% (84/6265)\n",
            "Train Accuracy of     8: 99.453% (5819/5851)\n",
            "Train Accuracy of     9: 0.000% ( 0/5949)\n",
            "\n",
            "Final Train  Accuracy: 18.187 (10912.0/60000.0)\n",
            "\n",
            "Round: 23... \tAverage Loss: 1.014\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.925938\n",
            "\n",
            "Train Accuracy of     0: 98.666% (5844/5923)\n",
            "Train Accuracy of     1: 60.412% (4073/6742)\n",
            "Train Accuracy of     2: 46.576% (2775/5958)\n",
            "Train Accuracy of     3: 72.256% (4430/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.572% (31/5421)\n",
            "Train Accuracy of     6: 36.381% (2153/5918)\n",
            "Train Accuracy of     7: 67.310% (4217/6265)\n",
            "Train Accuracy of     8: 20.441% (1196/5851)\n",
            "Train Accuracy of     9: 0.370% (22/5949)\n",
            "\n",
            "Final Train  Accuracy: 41.235 (24741.0/60000.0)\n",
            "\n",
            "Round: 24... \tAverage Loss: 1.227\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.375963\n",
            "\n",
            "Train Accuracy of     0: 35.506% (2103/5923)\n",
            "Train Accuracy of     1: 0.000% ( 0/6742)\n",
            "Train Accuracy of     2: 0.000% ( 0/5958)\n",
            "Train Accuracy of     3: 100.000% (6131/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 0.000% ( 0/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 0.050% ( 3/5949)\n",
            "\n",
            "Final Train  Accuracy: 13.728 (8237.0/60000.0)\n",
            "\n",
            "Round: 25... \tAverage Loss: 0.891\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.968656\n",
            "\n",
            "Train Accuracy of     0: 98.953% (5861/5923)\n",
            "Train Accuracy of     1: 78.953% (5323/6742)\n",
            "Train Accuracy of     2: 10.373% (618/5958)\n",
            "Train Accuracy of     3: 58.669% (3597/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.369% (20/5421)\n",
            "Train Accuracy of     6: 1.673% (99/5918)\n",
            "Train Accuracy of     7: 84.086% (5268/6265)\n",
            "Train Accuracy of     8: 0.103% ( 6/5851)\n",
            "Train Accuracy of     9: 1.278% (76/5949)\n",
            "\n",
            "Final Train  Accuracy: 34.780 (20868.0/60000.0)\n",
            "\n",
            "Round: 26... \tAverage Loss: 1.192\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.918158\n",
            "\n",
            "Train Accuracy of     0: 98.143% (5813/5923)\n",
            "Train Accuracy of     1: 71.388% (4813/6742)\n",
            "Train Accuracy of     2: 39.275% (2340/5958)\n",
            "Train Accuracy of     3: 11.532% (707/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 8.297% (491/5918)\n",
            "Train Accuracy of     7: 78.883% (4942/6265)\n",
            "Train Accuracy of     8: 1.812% (106/5851)\n",
            "Train Accuracy of     9: 70.684% (4205/5949)\n",
            "\n",
            "Final Train  Accuracy: 39.028 (23417.0/60000.0)\n",
            "\n",
            "Round: 27... \tAverage Loss: 1.056\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 2.003647\n",
            "\n",
            "Train Accuracy of     0: 97.400% (5769/5923)\n",
            "Train Accuracy of     1: 84.975% (5729/6742)\n",
            "Train Accuracy of     2: 66.415% (3957/5958)\n",
            "Train Accuracy of     3: 0.294% (18/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 17.641% (1044/5918)\n",
            "Train Accuracy of     7: 0.000% ( 0/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 94.117% (5599/5949)\n",
            "\n",
            "Final Train  Accuracy: 36.860 (22116.0/60000.0)\n",
            "\n",
            "Round: 28... \tAverage Loss: 0.908\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.886582\n",
            "\n",
            "Train Accuracy of     0: 85.160% (5044/5923)\n",
            "Train Accuracy of     1: 57.372% (3868/6742)\n",
            "Train Accuracy of     2: 81.890% (4879/5958)\n",
            "Train Accuracy of     3: 0.245% (15/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 0.018% ( 1/5421)\n",
            "Train Accuracy of     6: 1.065% (63/5918)\n",
            "Train Accuracy of     7: 52.019% (3259/6265)\n",
            "Train Accuracy of     8: 1.846% (108/5851)\n",
            "Train Accuracy of     9: 94.856% (5643/5949)\n",
            "\n",
            "Final Train  Accuracy: 38.133 (22880.0/60000.0)\n",
            "\n",
            "Round: 29... \tAverage Loss: 1.384\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.864038\n",
            "\n",
            "Train Accuracy of     0: 93.382% (5531/5923)\n",
            "Train Accuracy of     1: 71.952% (4851/6742)\n",
            "Train Accuracy of     2: 85.767% (5110/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 3.081% (180/5842)\n",
            "Train Accuracy of     5: 8.024% (435/5421)\n",
            "Train Accuracy of     6: 1.234% (73/5918)\n",
            "Train Accuracy of     7: 89.896% (5632/6265)\n",
            "Train Accuracy of     8: 0.239% (14/5851)\n",
            "Train Accuracy of     9: 15.851% (943/5949)\n",
            "\n",
            "Final Train  Accuracy: 37.948 (22769.0/60000.0)\n",
            "\n",
            "Round: 30... \tAverage Loss: 0.98\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.842282\n",
            "\n",
            "Train Accuracy of     0: 99.561% (5897/5923)\n",
            "Train Accuracy of     1: 86.161% (5809/6742)\n",
            "Train Accuracy of     2: 51.057% (3042/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 9.415% (550/5842)\n",
            "Train Accuracy of     5: 0.018% ( 1/5421)\n",
            "Train Accuracy of     6: 18.756% (1110/5918)\n",
            "Train Accuracy of     7: 77.542% (4858/6265)\n",
            "Train Accuracy of     8: 0.103% ( 6/5851)\n",
            "Train Accuracy of     9: 8.943% (532/5949)\n",
            "\n",
            "Final Train  Accuracy: 36.342 (21805.0/60000.0)\n",
            "\n",
            "Round: 31... \tAverage Loss: 0.962\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.830504\n",
            "\n",
            "Train Accuracy of     0: 97.721% (5788/5923)\n",
            "Train Accuracy of     1: 45.995% (3101/6742)\n",
            "Train Accuracy of     2: 81.504% (4856/5958)\n",
            "Train Accuracy of     3: 0.196% (12/6131)\n",
            "Train Accuracy of     4: 3.903% (228/5842)\n",
            "Train Accuracy of     5: 0.240% (13/5421)\n",
            "Train Accuracy of     6: 3.920% (232/5918)\n",
            "Train Accuracy of     7: 89.401% (5601/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 12.288% (731/5949)\n",
            "\n",
            "Final Train  Accuracy: 34.270 (20562.0/60000.0)\n",
            "\n",
            "Round: 32... \tAverage Loss: 0.933\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.795678\n",
            "\n",
            "Train Accuracy of     0: 97.282% (5762/5923)\n",
            "Train Accuracy of     1: 99.748% (6725/6742)\n",
            "Train Accuracy of     2: 13.461% (802/5958)\n",
            "Train Accuracy of     3: 1.011% (62/6131)\n",
            "Train Accuracy of     4: 0.599% (35/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 28.794% (1704/5918)\n",
            "Train Accuracy of     7: 51.125% (3203/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 42.276% (2515/5949)\n",
            "\n",
            "Final Train  Accuracy: 34.680 (20808.0/60000.0)\n",
            "\n",
            "Round: 33... \tAverage Loss: 0.932\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.885274\n",
            "\n",
            "Train Accuracy of     0: 98.075% (5809/5923)\n",
            "Train Accuracy of     1: 97.241% (6556/6742)\n",
            "Train Accuracy of     2: 62.471% (3722/5958)\n",
            "Train Accuracy of     3: 0.261% (16/6131)\n",
            "Train Accuracy of     4: 0.017% ( 1/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 2.247% (133/5918)\n",
            "Train Accuracy of     7: 51.955% (3255/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 86.351% (5137/5949)\n",
            "\n",
            "Final Train  Accuracy: 41.048 (24629.0/60000.0)\n",
            "\n",
            "Round: 34... \tAverage Loss: 0.896\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.826848\n",
            "\n",
            "Train Accuracy of     0: 88.384% (5235/5923)\n",
            "Train Accuracy of     1: 81.222% (5476/6742)\n",
            "Train Accuracy of     2: 4.146% (247/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 0.000% ( 0/5842)\n",
            "Train Accuracy of     5: 1.181% (64/5421)\n",
            "Train Accuracy of     6: 66.137% (3914/5918)\n",
            "Train Accuracy of     7: 95.435% (5979/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 31.501% (1874/5949)\n",
            "\n",
            "Final Train  Accuracy: 37.982 (22789.0/60000.0)\n",
            "\n",
            "Round: 35... \tAverage Loss: 1.152\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.803131\n",
            "\n",
            "Train Accuracy of     0: 78.930% (4675/5923)\n",
            "Train Accuracy of     1: 25.571% (1724/6742)\n",
            "Train Accuracy of     2: 2.064% (123/5958)\n",
            "Train Accuracy of     3: 0.000% ( 0/6131)\n",
            "Train Accuracy of     4: 0.171% (10/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 29.098% (1722/5918)\n",
            "Train Accuracy of     7: 79.282% (4967/6265)\n",
            "Train Accuracy of     8: 61.665% (3608/5851)\n",
            "Train Accuracy of     9: 83.527% (4969/5949)\n",
            "\n",
            "Final Train  Accuracy: 36.330 (21798.0/60000.0)\n",
            "\n",
            "Round: 36... \tAverage Loss: 1.108\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.658346\n",
            "\n",
            "Train Accuracy of     0: 86.291% (5111/5923)\n",
            "Train Accuracy of     1: 37.066% (2499/6742)\n",
            "Train Accuracy of     2: 49.463% (2947/5958)\n",
            "Train Accuracy of     3: 1.060% (65/6131)\n",
            "Train Accuracy of     4: 0.017% ( 1/5842)\n",
            "Train Accuracy of     5: 22.394% (1214/5421)\n",
            "Train Accuracy of     6: 61.626% (3647/5918)\n",
            "Train Accuracy of     7: 96.042% (6017/6265)\n",
            "Train Accuracy of     8: 69.031% (4039/5851)\n",
            "Train Accuracy of     9: 11.884% (707/5949)\n",
            "\n",
            "Final Train  Accuracy: 43.745 (26247.0/60000.0)\n",
            "\n",
            "Round: 37... \tAverage Loss: 0.86\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.723187\n",
            "\n",
            "Train Accuracy of     0: 80.736% (4782/5923)\n",
            "Train Accuracy of     1: 9.626% (649/6742)\n",
            "Train Accuracy of     2: 79.775% (4753/5958)\n",
            "Train Accuracy of     3: 0.016% ( 1/6131)\n",
            "Train Accuracy of     4: 1.660% (97/5842)\n",
            "Train Accuracy of     5: 6.678% (362/5421)\n",
            "Train Accuracy of     6: 49.121% (2907/5918)\n",
            "Train Accuracy of     7: 97.366% (6100/6265)\n",
            "Train Accuracy of     8: 4.153% (243/5851)\n",
            "Train Accuracy of     9: 4.253% (253/5949)\n",
            "\n",
            "Final Train  Accuracy: 33.578 (20147.0/60000.0)\n",
            "\n",
            "Round: 38... \tAverage Loss: 0.833\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.607563\n",
            "\n",
            "Train Accuracy of     0: 88.536% (5244/5923)\n",
            "Train Accuracy of     1: 75.838% (5113/6742)\n",
            "Train Accuracy of     2: 94.512% (5631/5958)\n",
            "Train Accuracy of     3: 2.088% (128/6131)\n",
            "Train Accuracy of     4: 0.976% (57/5842)\n",
            "Train Accuracy of     5: 40.491% (2195/5421)\n",
            "Train Accuracy of     6: 30.906% (1829/5918)\n",
            "Train Accuracy of     7: 81.516% (5107/6265)\n",
            "Train Accuracy of     8: 14.835% (868/5851)\n",
            "Train Accuracy of     9: 20.962% (1247/5949)\n",
            "\n",
            "Final Train  Accuracy: 45.698 (27419.0/60000.0)\n",
            "\n",
            "Round: 39... \tAverage Loss: 0.739\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.516773\n",
            "\n",
            "Train Accuracy of     0: 93.095% (5514/5923)\n",
            "Train Accuracy of     1: 99.481% (6707/6742)\n",
            "Train Accuracy of     2: 26.905% (1603/5958)\n",
            "Train Accuracy of     3: 29.131% (1786/6131)\n",
            "Train Accuracy of     4: 63.523% (3711/5842)\n",
            "Train Accuracy of     5: 46.431% (2517/5421)\n",
            "Train Accuracy of     6: 69.280% (4100/5918)\n",
            "Train Accuracy of     7: 71.828% (4500/6265)\n",
            "Train Accuracy of     8: 4.222% (247/5851)\n",
            "Train Accuracy of     9: 1.429% (85/5949)\n",
            "\n",
            "Final Train  Accuracy: 51.283 (30770.0/60000.0)\n",
            "\n",
            "Round: 40... \tAverage Loss: 0.897\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.648530\n",
            "\n",
            "Train Accuracy of     0: 95.560% (5660/5923)\n",
            "Train Accuracy of     1: 99.867% (6733/6742)\n",
            "Train Accuracy of     2: 0.034% ( 2/5958)\n",
            "Train Accuracy of     3: 36.389% (2231/6131)\n",
            "Train Accuracy of     4: 16.398% (958/5842)\n",
            "Train Accuracy of     5: 12.083% (655/5421)\n",
            "Train Accuracy of     6: 78.135% (4624/5918)\n",
            "Train Accuracy of     7: 33.536% (2101/6265)\n",
            "Train Accuracy of     8: 2.068% (121/5851)\n",
            "Train Accuracy of     9: 33.283% (1980/5949)\n",
            "\n",
            "Final Train  Accuracy: 41.775 (25065.0/60000.0)\n",
            "\n",
            "Round: 41... \tAverage Loss: 0.737\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.551322\n",
            "\n",
            "Train Accuracy of     0: 99.308% (5882/5923)\n",
            "Train Accuracy of     1: 99.110% (6682/6742)\n",
            "Train Accuracy of     2: 16.700% (995/5958)\n",
            "Train Accuracy of     3: 49.290% (3022/6131)\n",
            "Train Accuracy of     4: 75.026% (4383/5842)\n",
            "Train Accuracy of     5: 8.799% (477/5421)\n",
            "Train Accuracy of     6: 37.597% (2225/5918)\n",
            "Train Accuracy of     7: 49.657% (3111/6265)\n",
            "Train Accuracy of     8: 0.017% ( 1/5851)\n",
            "Train Accuracy of     9: 5.850% (348/5949)\n",
            "\n",
            "Final Train  Accuracy: 45.210 (27126.0/60000.0)\n",
            "\n",
            "Round: 42... \tAverage Loss: 0.786\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.864409\n",
            "\n",
            "Train Accuracy of     0: 99.949% (5920/5923)\n",
            "Train Accuracy of     1: 98.754% (6658/6742)\n",
            "Train Accuracy of     2: 3.223% (192/5958)\n",
            "Train Accuracy of     3: 11.368% (697/6131)\n",
            "Train Accuracy of     4: 3.971% (232/5842)\n",
            "Train Accuracy of     5: 0.295% (16/5421)\n",
            "Train Accuracy of     6: 32.933% (1949/5918)\n",
            "Train Accuracy of     7: 63.879% (4002/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 25.500% (1517/5949)\n",
            "\n",
            "Final Train  Accuracy: 35.305 (21183.0/60000.0)\n",
            "\n",
            "Round: 43... \tAverage Loss: 0.811\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.660321\n",
            "\n",
            "Train Accuracy of     0: 99.730% (5907/5923)\n",
            "Train Accuracy of     1: 97.212% (6554/6742)\n",
            "Train Accuracy of     2: 29.003% (1728/5958)\n",
            "Train Accuracy of     3: 10.651% (653/6131)\n",
            "Train Accuracy of     4: 21.037% (1229/5842)\n",
            "Train Accuracy of     5: 0.221% (12/5421)\n",
            "Train Accuracy of     6: 33.677% (1993/5918)\n",
            "Train Accuracy of     7: 26.560% (1664/6265)\n",
            "Train Accuracy of     8: 2.341% (137/5851)\n",
            "Train Accuracy of     9: 81.358% (4840/5949)\n",
            "\n",
            "Final Train  Accuracy: 41.195 (24717.0/60000.0)\n",
            "\n",
            "Round: 44... \tAverage Loss: 0.895\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.428523\n",
            "\n",
            "Train Accuracy of     0: 98.025% (5806/5923)\n",
            "Train Accuracy of     1: 90.611% (6109/6742)\n",
            "Train Accuracy of     2: 63.209% (3766/5958)\n",
            "Train Accuracy of     3: 84.179% (5161/6131)\n",
            "Train Accuracy of     4: 9.432% (551/5842)\n",
            "Train Accuracy of     5: 5.977% (324/5421)\n",
            "Train Accuracy of     6: 46.958% (2779/5918)\n",
            "Train Accuracy of     7: 51.237% (3210/6265)\n",
            "Train Accuracy of     8: 38.626% (2260/5851)\n",
            "Train Accuracy of     9: 64.414% (3832/5949)\n",
            "\n",
            "Final Train  Accuracy: 56.330 (33798.0/60000.0)\n",
            "\n",
            "Round: 45... \tAverage Loss: 0.769\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.697029\n",
            "\n",
            "Train Accuracy of     0: 93.095% (5514/5923)\n",
            "Train Accuracy of     1: 98.710% (6655/6742)\n",
            "Train Accuracy of     2: 35.448% (2112/5958)\n",
            "Train Accuracy of     3: 24.009% (1472/6131)\n",
            "Train Accuracy of     4: 0.034% ( 2/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 15.495% (917/5918)\n",
            "Train Accuracy of     7: 26.576% (1665/6265)\n",
            "Train Accuracy of     8: 0.598% (35/5851)\n",
            "Train Accuracy of     9: 98.168% (5840/5949)\n",
            "\n",
            "Final Train  Accuracy: 40.353 (24212.0/60000.0)\n",
            "\n",
            "Round: 46... \tAverage Loss: 0.68\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469\n",
            "60000\n",
            "Train Loss: 1.701212\n",
            "\n",
            "Train Accuracy of     0: 98.784% (5851/5923)\n",
            "Train Accuracy of     1: 98.724% (6656/6742)\n",
            "Train Accuracy of     2: 26.301% (1567/5958)\n",
            "Train Accuracy of     3: 38.085% (2335/6131)\n",
            "Train Accuracy of     4: 0.086% ( 5/5842)\n",
            "Train Accuracy of     5: 0.000% ( 0/5421)\n",
            "Train Accuracy of     6: 28.726% (1700/5918)\n",
            "Train Accuracy of     7: 37.925% (2376/6265)\n",
            "Train Accuracy of     8: 0.000% ( 0/5851)\n",
            "Train Accuracy of     9: 92.570% (5507/5949)\n",
            "\n",
            "Final Train  Accuracy: 43.328 (25997.0/60000.0)\n",
            "\n",
            "Round: 47... \tAverage Loss: 0.689\n",
            "\n",
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using sigma=1.8157373046875 and C=1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:646: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
            "  \"A ``sample_rate`` has been provided.\"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:230: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C68J-Kk14dB"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yQ9GiAZ15jE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4829b8-50f3-4488-8446-101b0e1c4b7d"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "testing(mnist_cnn_non_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79\n",
            "10000\n",
            "Train Loss: 2.188375\n",
            "\n",
            "Train Accuracy of     0: 63% (48/76)\n",
            "Train Accuracy of     1: 98% (89/90)\n",
            "Train Accuracy of     2:  0% ( 0/91)\n",
            "Train Accuracy of     3:  0% ( 0/73)\n",
            "Train Accuracy of     4:  0% ( 0/89)\n",
            "Train Accuracy of     5: 11% ( 8/68)\n",
            "Train Accuracy of     6:  0% ( 0/62)\n",
            "Train Accuracy of     7: 86% (70/81)\n",
            "Train Accuracy of     8:  0% ( 0/77)\n",
            "Train Accuracy of     9:  0% ( 0/83)\n",
            "\n",
            "Final Train  Accuracy: 27.215 (215.0/790.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_jifdzniuhm"
      },
      "source": [
        "## MNIST MLP on IID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh-te0Od2XGO"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmpWmKOQixVV"
      },
      "source": [
        "# number of training rounds\n",
        "rounds = 100\n",
        "# client fraction\n",
        "C = 0.1\n",
        "# number of clients\n",
        "K = 100\n",
        "# number of training passes on local dataset for each round\n",
        "E = 5\n",
        "# batch size\n",
        "batch_size = 10\n",
        "# learning Rate\n",
        "lr=0.03\n",
        "# dict containing different type of data partition\n",
        "data_dict = iid_partition(mnist_data_train, 100)\n",
        "# load model\n",
        "mnist_mlp = MNIST_2NN()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  mnist_mlp.cuda()\n",
        "\n",
        "mnist_mlp_iid_trained = training(mnist_mlp, rounds, batch_size, lr, mnist_data_train, data_dict, C, K, E, \"MNIST MLP on IID Dataset\", \"orange\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTBsL3-72PPd"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9G4j5L62OrS"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "testing(mnist_mlp_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8jzEyO0iywz"
      },
      "source": [
        "## MNIST MLP on Non IID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJFepr3y2bF-"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBKO44Hgi1Uh"
      },
      "source": [
        "# number of training rounds\n",
        "rounds = 100\n",
        "# client fraction\n",
        "C = 0.1\n",
        "# number of clients\n",
        "K = 100\n",
        "# number of training passes on local dataset for each roung\n",
        "E = 5\n",
        "# batch size\n",
        "batch_size = 10\n",
        "# learning Rate\n",
        "lr=0.05\n",
        "# dict containing different type of data partition\n",
        "data_dict = non_iid_partition(mnist_data_train, 100, 200, 300, 2)\n",
        "# load model\n",
        "mnist_mlp = MNIST_2NN()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  mnist_mlp.cuda()\n",
        "\n",
        "mnist_mlp_non_iid_trained = training(mnist_mlp, rounds, batch_size, lr, mnist_data_train, data_dict, C, K, E, \"MNIST MLP on Non-IID Dataset\", \"green\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmuQYPbF2mes"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tKMlJyF2nGN"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "testing(mnist_mlp_non_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}